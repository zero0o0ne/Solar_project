{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 2,
   "metadata": {},
   "outputs": [
    {
     "ename": "ImportError",
     "evalue": "Traceback (most recent call last):\n  File \"C:\\Users\\nikit\\anaconda3_64\\lib\\site-packages\\tensorflow\\python\\pywrap_tensorflow.py\", line 58, in <module>\n    from tensorflow.python.pywrap_tensorflow_internal import *\n  File \"C:\\Users\\nikit\\anaconda3_64\\lib\\site-packages\\tensorflow\\python\\pywrap_tensorflow_internal.py\", line 28, in <module>\n    _pywrap_tensorflow_internal = swig_import_helper()\n  File \"C:\\Users\\nikit\\anaconda3_64\\lib\\site-packages\\tensorflow\\python\\pywrap_tensorflow_internal.py\", line 24, in swig_import_helper\n    _mod = imp.load_module('_pywrap_tensorflow_internal', fp, pathname, description)\n  File \"C:\\Users\\nikit\\anaconda3_64\\lib\\imp.py\", line 242, in load_module\n    return load_dynamic(name, filename, file)\n  File \"C:\\Users\\nikit\\anaconda3_64\\lib\\imp.py\", line 342, in load_dynamic\n    return _load(spec)\nImportError: DLL load failed while importing _pywrap_tensorflow_internal: Файл подкачки слишком мал для завершения операции.\n\n\nFailed to load the native TensorFlow runtime.\n\nSee https://www.tensorflow.org/install/errors\n\nfor some common reasons and solutions.  Include the entire stack trace\nabove this error message when asking for help.",
     "output_type": "error",
     "traceback": [
      "\u001b[1;31m---------------------------------------------------------------------------\u001b[0m",
      "\u001b[1;31mImportError\u001b[0m                               Traceback (most recent call last)",
      "\u001b[1;32m~\\anaconda3_64\\lib\\site-packages\\tensorflow\\python\\pywrap_tensorflow.py\u001b[0m in \u001b[0;36m<module>\u001b[1;34m\u001b[0m\n\u001b[0;32m     57\u001b[0m \u001b[1;33m\u001b[0m\u001b[0m\n\u001b[1;32m---> 58\u001b[1;33m   \u001b[1;32mfrom\u001b[0m \u001b[0mtensorflow\u001b[0m\u001b[1;33m.\u001b[0m\u001b[0mpython\u001b[0m\u001b[1;33m.\u001b[0m\u001b[0mpywrap_tensorflow_internal\u001b[0m \u001b[1;32mimport\u001b[0m \u001b[1;33m*\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0m\u001b[0;32m     59\u001b[0m \u001b[1;33m\u001b[0m\u001b[0m\n",
      "\u001b[1;32m~\\anaconda3_64\\lib\\site-packages\\tensorflow\\python\\pywrap_tensorflow_internal.py\u001b[0m in \u001b[0;36m<module>\u001b[1;34m\u001b[0m\n\u001b[0;32m     27\u001b[0m             \u001b[1;32mreturn\u001b[0m \u001b[0m_mod\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[1;32m---> 28\u001b[1;33m     \u001b[0m_pywrap_tensorflow_internal\u001b[0m \u001b[1;33m=\u001b[0m \u001b[0mswig_import_helper\u001b[0m\u001b[1;33m(\u001b[0m\u001b[1;33m)\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0m\u001b[0;32m     29\u001b[0m     \u001b[1;32mdel\u001b[0m \u001b[0mswig_import_helper\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n",
      "\u001b[1;32m~\\anaconda3_64\\lib\\site-packages\\tensorflow\\python\\pywrap_tensorflow_internal.py\u001b[0m in \u001b[0;36mswig_import_helper\u001b[1;34m()\u001b[0m\n\u001b[0;32m     23\u001b[0m             \u001b[1;32mtry\u001b[0m\u001b[1;33m:\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[1;32m---> 24\u001b[1;33m                 \u001b[0m_mod\u001b[0m \u001b[1;33m=\u001b[0m \u001b[0mimp\u001b[0m\u001b[1;33m.\u001b[0m\u001b[0mload_module\u001b[0m\u001b[1;33m(\u001b[0m\u001b[1;34m'_pywrap_tensorflow_internal'\u001b[0m\u001b[1;33m,\u001b[0m \u001b[0mfp\u001b[0m\u001b[1;33m,\u001b[0m \u001b[0mpathname\u001b[0m\u001b[1;33m,\u001b[0m \u001b[0mdescription\u001b[0m\u001b[1;33m)\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0m\u001b[0;32m     25\u001b[0m             \u001b[1;32mfinally\u001b[0m\u001b[1;33m:\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n",
      "\u001b[1;32m~\\anaconda3_64\\lib\\imp.py\u001b[0m in \u001b[0;36mload_module\u001b[1;34m(name, file, filename, details)\u001b[0m\n\u001b[0;32m    241\u001b[0m         \u001b[1;32melse\u001b[0m\u001b[1;33m:\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[1;32m--> 242\u001b[1;33m             \u001b[1;32mreturn\u001b[0m \u001b[0mload_dynamic\u001b[0m\u001b[1;33m(\u001b[0m\u001b[0mname\u001b[0m\u001b[1;33m,\u001b[0m \u001b[0mfilename\u001b[0m\u001b[1;33m,\u001b[0m \u001b[0mfile\u001b[0m\u001b[1;33m)\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0m\u001b[0;32m    243\u001b[0m     \u001b[1;32melif\u001b[0m \u001b[0mtype_\u001b[0m \u001b[1;33m==\u001b[0m \u001b[0mPKG_DIRECTORY\u001b[0m\u001b[1;33m:\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n",
      "\u001b[1;32m~\\anaconda3_64\\lib\\imp.py\u001b[0m in \u001b[0;36mload_dynamic\u001b[1;34m(name, path, file)\u001b[0m\n\u001b[0;32m    341\u001b[0m             name=name, loader=loader, origin=path)\n\u001b[1;32m--> 342\u001b[1;33m         \u001b[1;32mreturn\u001b[0m \u001b[0m_load\u001b[0m\u001b[1;33m(\u001b[0m\u001b[0mspec\u001b[0m\u001b[1;33m)\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0m\u001b[0;32m    343\u001b[0m \u001b[1;33m\u001b[0m\u001b[0m\n",
      "\u001b[1;31mImportError\u001b[0m: DLL load failed while importing _pywrap_tensorflow_internal: Файл подкачки слишком мал для завершения операции.",
      "\nDuring handling of the above exception, another exception occurred:\n",
      "\u001b[1;31mImportError\u001b[0m                               Traceback (most recent call last)",
      "\u001b[1;32m<ipython-input-2-e5f94c8ebcec>\u001b[0m in \u001b[0;36m<module>\u001b[1;34m\u001b[0m\n\u001b[0;32m      1\u001b[0m \u001b[1;32mimport\u001b[0m \u001b[0mnumpy\u001b[0m \u001b[1;32mas\u001b[0m \u001b[0mnp\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0;32m      2\u001b[0m \u001b[1;32mimport\u001b[0m \u001b[0mmatplotlib\u001b[0m\u001b[1;33m.\u001b[0m\u001b[0mpyplot\u001b[0m \u001b[1;32mas\u001b[0m \u001b[0mplt\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[1;32m----> 3\u001b[1;33m \u001b[1;32mimport\u001b[0m \u001b[0mtensorflow\u001b[0m \u001b[1;32mas\u001b[0m \u001b[0mtf\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0m\u001b[0;32m      4\u001b[0m \u001b[1;32mimport\u001b[0m \u001b[0mpandas\u001b[0m \u001b[1;32mas\u001b[0m \u001b[0mpd\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0;32m      5\u001b[0m \u001b[1;32mfrom\u001b[0m \u001b[0mskimage\u001b[0m \u001b[1;32mimport\u001b[0m \u001b[0mio\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n",
      "\u001b[1;32m~\\anaconda3_64\\lib\\site-packages\\tensorflow\\__init__.py\u001b[0m in \u001b[0;36m<module>\u001b[1;34m\u001b[0m\n\u001b[0;32m     39\u001b[0m \u001b[1;32mimport\u001b[0m \u001b[0msys\u001b[0m \u001b[1;32mas\u001b[0m \u001b[0m_sys\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0;32m     40\u001b[0m \u001b[1;33m\u001b[0m\u001b[0m\n\u001b[1;32m---> 41\u001b[1;33m \u001b[1;32mfrom\u001b[0m \u001b[0mtensorflow\u001b[0m\u001b[1;33m.\u001b[0m\u001b[0mpython\u001b[0m\u001b[1;33m.\u001b[0m\u001b[0mtools\u001b[0m \u001b[1;32mimport\u001b[0m \u001b[0mmodule_util\u001b[0m \u001b[1;32mas\u001b[0m \u001b[0m_module_util\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0m\u001b[0;32m     42\u001b[0m \u001b[1;32mfrom\u001b[0m \u001b[0mtensorflow\u001b[0m\u001b[1;33m.\u001b[0m\u001b[0mpython\u001b[0m\u001b[1;33m.\u001b[0m\u001b[0mutil\u001b[0m\u001b[1;33m.\u001b[0m\u001b[0mlazy_loader\u001b[0m \u001b[1;32mimport\u001b[0m \u001b[0mLazyLoader\u001b[0m \u001b[1;32mas\u001b[0m \u001b[0m_LazyLoader\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0;32m     43\u001b[0m \u001b[1;33m\u001b[0m\u001b[0m\n",
      "\u001b[1;32m~\\anaconda3_64\\lib\\site-packages\\tensorflow\\python\\__init__.py\u001b[0m in \u001b[0;36m<module>\u001b[1;34m\u001b[0m\n\u001b[0;32m     48\u001b[0m \u001b[1;32mimport\u001b[0m \u001b[0mnumpy\u001b[0m \u001b[1;32mas\u001b[0m \u001b[0mnp\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0;32m     49\u001b[0m \u001b[1;33m\u001b[0m\u001b[0m\n\u001b[1;32m---> 50\u001b[1;33m \u001b[1;32mfrom\u001b[0m \u001b[0mtensorflow\u001b[0m\u001b[1;33m.\u001b[0m\u001b[0mpython\u001b[0m \u001b[1;32mimport\u001b[0m \u001b[0mpywrap_tensorflow\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0m\u001b[0;32m     51\u001b[0m \u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0;32m     52\u001b[0m \u001b[1;31m# Protocol buffers\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n",
      "\u001b[1;32m~\\anaconda3_64\\lib\\site-packages\\tensorflow\\python\\pywrap_tensorflow.py\u001b[0m in \u001b[0;36m<module>\u001b[1;34m\u001b[0m\n\u001b[0;32m     67\u001b[0m \u001b[1;32mfor\u001b[0m \u001b[0msome\u001b[0m \u001b[0mcommon\u001b[0m \u001b[0mreasons\u001b[0m \u001b[1;32mand\u001b[0m \u001b[0msolutions\u001b[0m\u001b[1;33m.\u001b[0m  \u001b[0mInclude\u001b[0m \u001b[0mthe\u001b[0m \u001b[0mentire\u001b[0m \u001b[0mstack\u001b[0m \u001b[0mtrace\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0;32m     68\u001b[0m above this error message when asking for help.\"\"\" % traceback.format_exc()\n\u001b[1;32m---> 69\u001b[1;33m   \u001b[1;32mraise\u001b[0m \u001b[0mImportError\u001b[0m\u001b[1;33m(\u001b[0m\u001b[0mmsg\u001b[0m\u001b[1;33m)\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0m\u001b[0;32m     70\u001b[0m \u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0;32m     71\u001b[0m \u001b[1;31m# pylint: enable=wildcard-import,g-import-not-at-top,unused-import,line-too-long\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n",
      "\u001b[1;31mImportError\u001b[0m: Traceback (most recent call last):\n  File \"C:\\Users\\nikit\\anaconda3_64\\lib\\site-packages\\tensorflow\\python\\pywrap_tensorflow.py\", line 58, in <module>\n    from tensorflow.python.pywrap_tensorflow_internal import *\n  File \"C:\\Users\\nikit\\anaconda3_64\\lib\\site-packages\\tensorflow\\python\\pywrap_tensorflow_internal.py\", line 28, in <module>\n    _pywrap_tensorflow_internal = swig_import_helper()\n  File \"C:\\Users\\nikit\\anaconda3_64\\lib\\site-packages\\tensorflow\\python\\pywrap_tensorflow_internal.py\", line 24, in swig_import_helper\n    _mod = imp.load_module('_pywrap_tensorflow_internal', fp, pathname, description)\n  File \"C:\\Users\\nikit\\anaconda3_64\\lib\\imp.py\", line 242, in load_module\n    return load_dynamic(name, filename, file)\n  File \"C:\\Users\\nikit\\anaconda3_64\\lib\\imp.py\", line 342, in load_dynamic\n    return _load(spec)\nImportError: DLL load failed while importing _pywrap_tensorflow_internal: Файл подкачки слишком мал для завершения операции.\n\n\nFailed to load the native TensorFlow runtime.\n\nSee https://www.tensorflow.org/install/errors\n\nfor some common reasons and solutions.  Include the entire stack trace\nabove this error message when asking for help."
     ]
    }
   ],
   "source": [
    "import numpy as np\n",
    "import matplotlib.pyplot as plt\n",
    "import tensorflow as tf\n",
    "import pandas as pd\n",
    "from skimage import io\n",
    "from skimage import transform\n",
    "from sklearn.utils import shuffle\n",
    "from keras.utils import np_utils\n",
    "import scipy.stats\n",
    "import copy"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "frame = pd.read_csv('samples_with_marks.csv')\n",
    "\n",
    "filenames = np.asarray(frame['filename'])\n",
    "result_ = np.asarray(frame['result'])\n",
    "\n",
    "Y_ = np.ndarray((filenames.size, 32, 32))\n",
    "for i in range(filenames.size):\n",
    "    X = io.imread(filenames[i], as_gray = True) \n",
    "    #максимальная длина картинки в наших данных - 31\n",
    "    X = np.r_[np.c_[X, np.ones((X.size // X[1].size, 32 - X[1].size))], np.ones((32-X.size // X[1].size, 32))] \n",
    "    Y_[i] = X\n",
    "Y_ = 1-Y_\n",
    "Y_ = Y_.astype('float32')\n",
    "\n",
    "waste = [i for i in range(result_.shape[0]) if result_[i] == 10]\n",
    "result_ = np.delete(result_, waste, axis = 0)\n",
    "Y_ = np.delete(Y_, waste, axis = 0)\n",
    "\n",
    "\n",
    "Y_test = Y_[::5]\n",
    "result_test = result_[::5]     \n",
    "Y = np.delete(Y_, list(range(0, Y_.shape[0], 5)), axis=0)\n",
    "result = np.delete(result_, list(range(0, result_.shape[0], 5)), axis=0)\n",
    "\n",
    "\n",
    "num_train = 6000\n",
    "num_test = 1000\n",
    "height, width, depth = 32, 32, 1 \n",
    "num_classes = 10\n",
    "\n",
    "(X_train, y_train), (X_test, y_test) = tf.keras.datasets.mnist.load_data()\n",
    "\n",
    "X_train = X_train.astype('float32') \n",
    "Y_train = np.ndarray((num_train, height, width))\n",
    "for i in range(num_train):\n",
    "    Y_train[i] = np.r_[np.c_[X_train[i], np.ones((28, 4))], np.ones((4, 32))]\n",
    "Y_train /= 255\n",
    "y_train = y_train[:6000]\n",
    "\n",
    "\n",
    "X_MNIST = Y_train[:Y_train.shape[0] // 2]\n",
    "X = Y\n",
    "X_noised = Y[Y.shape[0] // 2:]\n",
    "#X_rotate = Y[::2]\n",
    "#X_MNIST_rotate = Y_train[::2]\n",
    "#X_inverted = 1 - Y\n",
    "\n",
    "y_MNIST = y_train[:Y_train.shape[0] // 2]\n",
    "y = result\n",
    "y_noised = result[Y.shape[0] // 2:]\n",
    "#y_rotate = result[::2]\n",
    "#y_MNIST_rotate = y_train[::2]\n",
    "#y_inverted = result\n",
    "\n",
    "for i in range(X_noised.shape[0]):\n",
    "    X_noised[i] = transform.rotate(transform.rotate(X_noised[i], 60), -60)\n",
    "#for i in range(X_rotate.shape[0]):\n",
    "    #X_rotate[i] = transform.rotate(X_rotate[i], 7.31 * i)\n",
    "#for i in range(X_MNIST_rotate.shape[0]):\n",
    "    #X_MNIST_rotate[i] = transform.rotate(X_MNIST_rotate[i], 7.31 * i)\n",
    "    \n",
    "#X_tr = np.concatenate((X_MNIST, X, X_noised, X_rotate, X_MNIST_rotate, X_inverted))\n",
    "#y_tr = np.concatenate((y_MNIST, y, y_noised, y_rotate, y_MNIST_rotate, y_inverted))\n",
    "X_tr = np.concatenate((X_MNIST, X, X_noised))\n",
    "y_tr = np.concatenate((y_MNIST, y, y_noised))\n",
    "data, ans = shuffle(X_tr, y_tr)\n",
    "\n",
    "\n",
    "num_samples = 5000\n",
    "meta_data, meta_ans = data[:num_samples], ans[:num_samples]\n",
    "data, ans = data[:num_samples], ans[:num_samples]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "metadata": {},
   "outputs": [],
   "source": [
    "model_0 = tf.keras.models.Sequential([\n",
    "    tf.keras.layers.Conv2D(input_shape=(32, 32, 1), filters=32, kernel_size=(5,5), padding='same', activation='relu'),\n",
    "    tf.keras.layers.MaxPool2D(pool_size=(2, 2)),\n",
    "    tf.keras.layers.Conv2D(filters=64, kernel_size=(5,5), padding='same', activation='relu'),\n",
    "    tf.keras.layers.MaxPool2D(pool_size=(2, 2)),\n",
    "    tf.keras.layers.Flatten(),\n",
    "    tf.keras.layers.Dense(512, activation=tf.nn.relu),\n",
    "    tf.keras.layers.Dense(num_classes, activation=tf.nn.softmax)\n",
    "])\n",
    "\n",
    "model_1 = tf.keras.models.Sequential([\n",
    "    tf.keras.layers.Conv2D(input_shape=(32, 32, 1), filters=32, kernel_size=(5,5), padding='same', activation='relu'),\n",
    "    tf.keras.layers.MaxPool2D(pool_size=(2, 2)),\n",
    "    tf.keras.layers.Conv2D(filters=64, kernel_size=(5,5), padding='same', activation='relu'),\n",
    "    tf.keras.layers.MaxPool2D(pool_size=(2, 2)),\n",
    "    tf.keras.layers.Flatten(),\n",
    "    tf.keras.layers.Dense(512, activation=tf.nn.relu),\n",
    "    tf.keras.layers.Dense(num_classes, activation=tf.nn.softmax)\n",
    "])\n",
    "\n",
    "model_2 = tf.keras.models.Sequential([\n",
    "    tf.keras.layers.Conv2D(input_shape=(32, 32, 1), filters=32, kernel_size=(5,5), padding='same', activation='relu'),\n",
    "    tf.keras.layers.MaxPool2D(pool_size=(2, 2)),\n",
    "    tf.keras.layers.Conv2D(filters=64, kernel_size=(5,5), padding='same', activation='relu'),\n",
    "    tf.keras.layers.MaxPool2D(pool_size=(2, 2)),\n",
    "    tf.keras.layers.Flatten(),\n",
    "    tf.keras.layers.Dense(512, activation=tf.nn.relu),\n",
    "    tf.keras.layers.Dense(num_classes, activation=tf.nn.softmax)\n",
    "])\n",
    "\n",
    "model_3 = tf.keras.models.Sequential([\n",
    "    tf.keras.layers.Conv2D(input_shape=(32, 32, 1), filters=32, kernel_size=(5,5), padding='same', activation='relu'),\n",
    "    tf.keras.layers.MaxPool2D(pool_size=(2, 2)),\n",
    "    tf.keras.layers.Conv2D(filters=64, kernel_size=(5,5), padding='same', activation='relu'),\n",
    "    tf.keras.layers.MaxPool2D(pool_size=(2, 2)),\n",
    "    tf.keras.layers.Flatten(),\n",
    "    tf.keras.layers.Dense(512, activation=tf.nn.relu),\n",
    "    tf.keras.layers.Dense(num_classes, activation=tf.nn.softmax)\n",
    "])\n",
    "\n",
    "model_4 = tf.keras.models.Sequential([\n",
    "    tf.keras.layers.Conv2D(input_shape=(32, 32, 1), filters=32, kernel_size=(5,5), padding='same', activation='relu'),\n",
    "    tf.keras.layers.MaxPool2D(pool_size=(2, 2)),\n",
    "    tf.keras.layers.Conv2D(filters=64, kernel_size=(5,5), padding='same', activation='relu'),\n",
    "    tf.keras.layers.MaxPool2D(pool_size=(2, 2)),\n",
    "    tf.keras.layers.Flatten(),\n",
    "    tf.keras.layers.Dense(512, activation=tf.nn.relu),\n",
    "    tf.keras.layers.Dense(num_classes, activation=tf.nn.softmax)\n",
    "])\n",
    "\n",
    "model_5 = tf.keras.models.Sequential([\n",
    "    tf.keras.layers.Conv2D(input_shape=(32, 32, 1), filters=32, kernel_size=(5,5), padding='same', activation='relu'),\n",
    "    tf.keras.layers.MaxPool2D(pool_size=(2, 2)),\n",
    "    tf.keras.layers.Conv2D(filters=64, kernel_size=(5,5), padding='same', activation='relu'),\n",
    "    tf.keras.layers.MaxPool2D(pool_size=(2, 2)),\n",
    "    tf.keras.layers.Flatten(),\n",
    "    tf.keras.layers.Dense(512, activation=tf.nn.relu),\n",
    "    tf.keras.layers.Dense(num_classes, activation=tf.nn.softmax)\n",
    "])\n",
    "\n",
    "model_6 = tf.keras.models.Sequential([\n",
    "    tf.keras.layers.Conv2D(input_shape=(32, 32, 1), filters=32, kernel_size=(5,5), padding='same', activation='relu'),\n",
    "    tf.keras.layers.MaxPool2D(pool_size=(2, 2)),\n",
    "    tf.keras.layers.Conv2D(filters=64, kernel_size=(5,5), padding='same', activation='relu'),\n",
    "    tf.keras.layers.MaxPool2D(pool_size=(2, 2)),\n",
    "    tf.keras.layers.Flatten(),\n",
    "    tf.keras.layers.Dense(512, activation=tf.nn.relu),\n",
    "    tf.keras.layers.Dense(num_classes, activation=tf.nn.softmax)\n",
    "])\n",
    "\n",
    "model_7 = tf.keras.models.Sequential([\n",
    "    tf.keras.layers.Conv2D(input_shape=(32, 32, 1), filters=32, kernel_size=(5,5), padding='same', activation='relu'),\n",
    "    tf.keras.layers.MaxPool2D(pool_size=(2, 2)),\n",
    "    tf.keras.layers.Conv2D(filters=64, kernel_size=(5,5), padding='same', activation='relu'),\n",
    "    tf.keras.layers.MaxPool2D(pool_size=(2, 2)),\n",
    "    tf.keras.layers.Flatten(),\n",
    "    tf.keras.layers.Dense(512, activation=tf.nn.relu),\n",
    "    tf.keras.layers.Dense(num_classes, activation=tf.nn.softmax)\n",
    "])\n",
    "\n",
    "model_8 = tf.keras.models.Sequential([\n",
    "    tf.keras.layers.Conv2D(input_shape=(32, 32, 1), filters=32, kernel_size=(5,5), padding='same', activation='relu'),\n",
    "    tf.keras.layers.MaxPool2D(pool_size=(2, 2)),\n",
    "    tf.keras.layers.Conv2D(filters=64, kernel_size=(5,5), padding='same', activation='relu'),\n",
    "    tf.keras.layers.MaxPool2D(pool_size=(2, 2)),\n",
    "    tf.keras.layers.Flatten(),\n",
    "    tf.keras.layers.Dense(512, activation=tf.nn.relu),\n",
    "    tf.keras.layers.Dense(num_classes, activation=tf.nn.softmax)\n",
    "])\n",
    "\n",
    "model_9 = tf.keras.models.Sequential([\n",
    "    tf.keras.layers.Conv2D(input_shape=(32, 32, 1), filters=32, kernel_size=(5,5), padding='same', activation='relu'),\n",
    "    tf.keras.layers.MaxPool2D(pool_size=(2, 2)),\n",
    "    tf.keras.layers.Conv2D(filters=64, kernel_size=(5,5), padding='same', activation='relu'),\n",
    "    tf.keras.layers.MaxPool2D(pool_size=(2, 2)),\n",
    "    tf.keras.layers.Flatten(),\n",
    "    tf.keras.layers.Dense(512, activation=tf.nn.relu),\n",
    "    tf.keras.layers.Dense(num_classes, activation=tf.nn.softmax)\n",
    "])\n",
    "\n",
    "model_10 = tf.keras.models.Sequential([\n",
    "    tf.keras.layers.Conv2D(input_shape=(32, 32, 1), filters=32, kernel_size=(5,5), padding='same', activation='relu'),\n",
    "    tf.keras.layers.MaxPool2D(pool_size=(2, 2)),\n",
    "    tf.keras.layers.Conv2D(filters=64, kernel_size=(5,5), padding='same', activation='relu'),\n",
    "    tf.keras.layers.MaxPool2D(pool_size=(2, 2)),\n",
    "    tf.keras.layers.Flatten(),\n",
    "    tf.keras.layers.Dense(512, activation=tf.nn.relu),\n",
    "    tf.keras.layers.Dense(num_classes, activation=tf.nn.softmax)\n",
    "])\n",
    "\n",
    "model_11 = tf.keras.models.Sequential([\n",
    "    tf.keras.layers.Conv2D(input_shape=(32, 32, 1), filters=32, kernel_size=(5,5), padding='same', activation='relu'),\n",
    "    tf.keras.layers.MaxPool2D(pool_size=(2, 2)),\n",
    "    tf.keras.layers.Conv2D(filters=64, kernel_size=(5,5), padding='same', activation='relu'),\n",
    "    tf.keras.layers.MaxPool2D(pool_size=(2, 2)),\n",
    "    tf.keras.layers.Flatten(),\n",
    "    tf.keras.layers.Dense(512, activation=tf.nn.relu),\n",
    "    tf.keras.layers.Dense(num_classes, activation=tf.nn.softmax)\n",
    "])\n",
    "\n",
    "model_12 = tf.keras.models.Sequential([\n",
    "    tf.keras.layers.Conv2D(input_shape=(32, 32, 1), filters=32, kernel_size=(5,5), padding='same', activation='relu'),\n",
    "    tf.keras.layers.MaxPool2D(pool_size=(2, 2)),\n",
    "    tf.keras.layers.Conv2D(filters=64, kernel_size=(5,5), padding='same', activation='relu'),\n",
    "    tf.keras.layers.MaxPool2D(pool_size=(2, 2)),\n",
    "    tf.keras.layers.Flatten(),\n",
    "    tf.keras.layers.Dense(512, activation=tf.nn.relu),\n",
    "    tf.keras.layers.Dense(num_classes, activation=tf.nn.softmax)\n",
    "])\n",
    "\n",
    "model_13 = tf.keras.models.Sequential([\n",
    "    tf.keras.layers.Conv2D(input_shape=(32, 32, 1), filters=32, kernel_size=(5,5), padding='same', activation='relu'),\n",
    "    tf.keras.layers.MaxPool2D(pool_size=(2, 2)),\n",
    "    tf.keras.layers.Conv2D(filters=64, kernel_size=(5,5), padding='same', activation='relu'),\n",
    "    tf.keras.layers.MaxPool2D(pool_size=(2, 2)),\n",
    "    tf.keras.layers.Flatten(),\n",
    "    tf.keras.layers.Dense(512, activation=tf.nn.relu),\n",
    "    tf.keras.layers.Dense(num_classes, activation=tf.nn.softmax)\n",
    "])\n",
    "\n",
    "model_14 = tf.keras.models.Sequential([\n",
    "    tf.keras.layers.Conv2D(input_shape=(32, 32, 1), filters=32, kernel_size=(5,5), padding='same', activation='relu'),\n",
    "    tf.keras.layers.MaxPool2D(pool_size=(2, 2)),\n",
    "    tf.keras.layers.Conv2D(filters=64, kernel_size=(5,5), padding='same', activation='relu'),\n",
    "    tf.keras.layers.MaxPool2D(pool_size=(2, 2)),\n",
    "    tf.keras.layers.Flatten(),\n",
    "    tf.keras.layers.Dense(512, activation=tf.nn.relu),\n",
    "    tf.keras.layers.Dense(num_classes, activation=tf.nn.softmax)\n",
    "])\n",
    "\n",
    "model_15 = tf.keras.models.Sequential([\n",
    "    tf.keras.layers.Conv2D(input_shape=(32, 32, 1), filters=32, kernel_size=(5,5), padding='same', activation='relu'),\n",
    "    tf.keras.layers.MaxPool2D(pool_size=(2, 2)),\n",
    "    tf.keras.layers.Conv2D(filters=64, kernel_size=(5,5), padding='same', activation='relu'),\n",
    "    tf.keras.layers.MaxPool2D(pool_size=(2, 2)),\n",
    "    tf.keras.layers.Flatten(),\n",
    "    tf.keras.layers.Dense(512, activation=tf.nn.relu),\n",
    "    tf.keras.layers.Dense(num_classes, activation=tf.nn.softmax)\n",
    "])\n",
    "\n",
    "model_16 = tf.keras.models.Sequential([\n",
    "    tf.keras.layers.Conv2D(input_shape=(32, 32, 1), filters=32, kernel_size=(5,5), padding='same', activation='relu'),\n",
    "    tf.keras.layers.MaxPool2D(pool_size=(2, 2)),\n",
    "    tf.keras.layers.Conv2D(filters=64, kernel_size=(5,5), padding='same', activation='relu'),\n",
    "    tf.keras.layers.MaxPool2D(pool_size=(2, 2)),\n",
    "    tf.keras.layers.Flatten(),\n",
    "    tf.keras.layers.Dense(512, activation=tf.nn.relu),\n",
    "    tf.keras.layers.Dense(num_classes, activation=tf.nn.softmax)\n",
    "])\n",
    "\n",
    "model_17 = tf.keras.models.Sequential([\n",
    "    tf.keras.layers.Conv2D(input_shape=(32, 32, 1), filters=32, kernel_size=(5,5), padding='same', activation='relu'),\n",
    "    tf.keras.layers.MaxPool2D(pool_size=(2, 2)),\n",
    "    tf.keras.layers.Conv2D(filters=64, kernel_size=(5,5), padding='same', activation='relu'),\n",
    "    tf.keras.layers.MaxPool2D(pool_size=(2, 2)),\n",
    "    tf.keras.layers.Flatten(),\n",
    "    tf.keras.layers.Dense(512, activation=tf.nn.relu),\n",
    "    tf.keras.layers.Dense(num_classes, activation=tf.nn.softmax)\n",
    "])\n",
    "\n",
    "model_18 = tf.keras.models.Sequential([\n",
    "    tf.keras.layers.Conv2D(input_shape=(32, 32, 1), filters=32, kernel_size=(5,5), padding='same', activation='relu'),\n",
    "    tf.keras.layers.MaxPool2D(pool_size=(2, 2)),\n",
    "    tf.keras.layers.Conv2D(filters=64, kernel_size=(5,5), padding='same', activation='relu'),\n",
    "    tf.keras.layers.MaxPool2D(pool_size=(2, 2)),\n",
    "    tf.keras.layers.Flatten(),\n",
    "    tf.keras.layers.Dense(512, activation=tf.nn.relu),\n",
    "    tf.keras.layers.Dense(num_classes, activation=tf.nn.softmax)\n",
    "])\n",
    "\n",
    "model_19 = tf.keras.models.Sequential([\n",
    "    tf.keras.layers.Conv2D(input_shape=(32, 32, 1), filters=32, kernel_size=(5,5), padding='same', activation='relu'),\n",
    "    tf.keras.layers.MaxPool2D(pool_size=(2, 2)),\n",
    "    tf.keras.layers.Conv2D(filters=64, kernel_size=(5,5), padding='same', activation='relu'),\n",
    "    tf.keras.layers.MaxPool2D(pool_size=(2, 2)),\n",
    "    tf.keras.layers.Flatten(),\n",
    "    tf.keras.layers.Dense(512, activation=tf.nn.relu),\n",
    "    tf.keras.layers.Dense(num_classes, activation=tf.nn.softmax)\n",
    "])\n",
    "\n",
    "model_20 = tf.keras.models.Sequential([\n",
    "    tf.keras.layers.Conv2D(input_shape=(32, 32, 1), filters=32, kernel_size=(5,5), padding='same', activation='relu'),\n",
    "    tf.keras.layers.MaxPool2D(pool_size=(2, 2)),\n",
    "    tf.keras.layers.Conv2D(filters=64, kernel_size=(5,5), padding='same', activation='relu'),\n",
    "    tf.keras.layers.MaxPool2D(pool_size=(2, 2)),\n",
    "    tf.keras.layers.Flatten(),\n",
    "    tf.keras.layers.Dense(512, activation=tf.nn.relu),\n",
    "    tf.keras.layers.Dense(num_classes, activation=tf.nn.softmax)\n",
    "])\n",
    "\n",
    "model_21 = tf.keras.models.Sequential([\n",
    "    tf.keras.layers.Conv2D(input_shape=(32, 32, 1), filters=32, kernel_size=(5,5), padding='same', activation='relu'),\n",
    "    tf.keras.layers.MaxPool2D(pool_size=(2, 2)),\n",
    "    tf.keras.layers.Conv2D(filters=64, kernel_size=(5,5), padding='same', activation='relu'),\n",
    "    tf.keras.layers.MaxPool2D(pool_size=(2, 2)),\n",
    "    tf.keras.layers.Flatten(),\n",
    "    tf.keras.layers.Dense(512, activation=tf.nn.relu),\n",
    "    tf.keras.layers.Dense(num_classes, activation=tf.nn.softmax)\n",
    "])\n",
    "\n",
    "model_22 = tf.keras.models.Sequential([\n",
    "    tf.keras.layers.Conv2D(input_shape=(32, 32, 1), filters=32, kernel_size=(5,5), padding='same', activation='relu'),\n",
    "    tf.keras.layers.MaxPool2D(pool_size=(2, 2)),\n",
    "    tf.keras.layers.Conv2D(filters=64, kernel_size=(5,5), padding='same', activation='relu'),\n",
    "    tf.keras.layers.MaxPool2D(pool_size=(2, 2)),\n",
    "    tf.keras.layers.Flatten(),\n",
    "    tf.keras.layers.Dense(512, activation=tf.nn.relu),\n",
    "    tf.keras.layers.Dense(num_classes, activation=tf.nn.softmax)\n",
    "])\n",
    "\n",
    "model_23 = tf.keras.models.Sequential([\n",
    "    tf.keras.layers.Conv2D(input_shape=(32, 32, 1), filters=32, kernel_size=(5,5), padding='same', activation='relu'),\n",
    "    tf.keras.layers.MaxPool2D(pool_size=(2, 2)),\n",
    "    tf.keras.layers.Conv2D(filters=64, kernel_size=(5,5), padding='same', activation='relu'),\n",
    "    tf.keras.layers.MaxPool2D(pool_size=(2, 2)),\n",
    "    tf.keras.layers.Flatten(),\n",
    "    tf.keras.layers.Dense(512, activation=tf.nn.relu),\n",
    "    tf.keras.layers.Dense(num_classes, activation=tf.nn.softmax)\n",
    "])\n",
    "\n",
    "model_24 = tf.keras.models.Sequential([\n",
    "    tf.keras.layers.Conv2D(input_shape=(32, 32, 1), filters=32, kernel_size=(5,5), padding='same', activation='relu'),\n",
    "    tf.keras.layers.MaxPool2D(pool_size=(2, 2)),\n",
    "    tf.keras.layers.Conv2D(filters=64, kernel_size=(5,5), padding='same', activation='relu'),\n",
    "    tf.keras.layers.MaxPool2D(pool_size=(2, 2)),\n",
    "    tf.keras.layers.Flatten(),\n",
    "    tf.keras.layers.Dense(512, activation=tf.nn.relu),\n",
    "    tf.keras.layers.Dense(num_classes, activation=tf.nn.softmax)\n",
    "])\n",
    "\n",
    "model_25 = tf.keras.models.Sequential([\n",
    "    tf.keras.layers.Conv2D(input_shape=(32, 32, 1), filters=32, kernel_size=(5,5), padding='same', activation='relu'),\n",
    "    tf.keras.layers.MaxPool2D(pool_size=(2, 2)),\n",
    "    tf.keras.layers.Conv2D(filters=64, kernel_size=(5,5), padding='same', activation='relu'),\n",
    "    tf.keras.layers.MaxPool2D(pool_size=(2, 2)),\n",
    "    tf.keras.layers.Flatten(),\n",
    "    tf.keras.layers.Dense(512, activation=tf.nn.relu),\n",
    "    tf.keras.layers.Dense(num_classes, activation=tf.nn.softmax)\n",
    "])\n",
    "\n",
    "model_26 = tf.keras.models.Sequential([\n",
    "    tf.keras.layers.Conv2D(input_shape=(32, 32, 1), filters=32, kernel_size=(5,5), padding='same', activation='relu'),\n",
    "    tf.keras.layers.MaxPool2D(pool_size=(2, 2)),\n",
    "    tf.keras.layers.Conv2D(filters=64, kernel_size=(5,5), padding='same', activation='relu'),\n",
    "    tf.keras.layers.MaxPool2D(pool_size=(2, 2)),\n",
    "    tf.keras.layers.Flatten(),\n",
    "    tf.keras.layers.Dense(512, activation=tf.nn.relu),\n",
    "    tf.keras.layers.Dense(num_classes, activation=tf.nn.softmax)\n",
    "])\n",
    "\n",
    "model_27 = tf.keras.models.Sequential([\n",
    "    tf.keras.layers.Conv2D(input_shape=(32, 32, 1), filters=32, kernel_size=(5,5), padding='same', activation='relu'),\n",
    "    tf.keras.layers.MaxPool2D(pool_size=(2, 2)),\n",
    "    tf.keras.layers.Conv2D(filters=64, kernel_size=(5,5), padding='same', activation='relu'),\n",
    "    tf.keras.layers.MaxPool2D(pool_size=(2, 2)),\n",
    "    tf.keras.layers.Flatten(),\n",
    "    tf.keras.layers.Dense(512, activation=tf.nn.relu),\n",
    "    tf.keras.layers.Dense(num_classes, activation=tf.nn.softmax)\n",
    "])\n",
    "\n",
    "model_28 = tf.keras.models.Sequential([\n",
    "    tf.keras.layers.Conv2D(input_shape=(32, 32, 1), filters=32, kernel_size=(5,5), padding='same', activation='relu'),\n",
    "    tf.keras.layers.MaxPool2D(pool_size=(2, 2)),\n",
    "    tf.keras.layers.Conv2D(filters=64, kernel_size=(5,5), padding='same', activation='relu'),\n",
    "    tf.keras.layers.MaxPool2D(pool_size=(2, 2)),\n",
    "    tf.keras.layers.Flatten(),\n",
    "    tf.keras.layers.Dense(512, activation=tf.nn.relu),\n",
    "    tf.keras.layers.Dense(num_classes, activation=tf.nn.softmax)\n",
    "])\n",
    "\n",
    "model_29 = tf.keras.models.Sequential([\n",
    "    tf.keras.layers.Conv2D(input_shape=(32, 32, 1), filters=32, kernel_size=(5,5), padding='same', activation='relu'),\n",
    "    tf.keras.layers.MaxPool2D(pool_size=(2, 2)),\n",
    "    tf.keras.layers.Conv2D(filters=64, kernel_size=(5,5), padding='same', activation='relu'),\n",
    "    tf.keras.layers.MaxPool2D(pool_size=(2, 2)),\n",
    "    tf.keras.layers.Flatten(),\n",
    "    tf.keras.layers.Dense(512, activation=tf.nn.relu),\n",
    "    tf.keras.layers.Dense(num_classes, activation=tf.nn.softmax)\n",
    "])\n",
    "\n",
    "models = [model_0, model_1, model_2, model_3, model_4, model_5, model_6, model_7, model_8, model_9, model_10, model_11, model_12, model_13, model_14, model_15, model_16, model_17, model_18, model_19, model_20, model_21, model_22, model_23, model_24, model_25, model_26, model_27, model_28, model_29]\n",
    "num_mod = 30"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "1000/1000 [==============================] - 4s 4ms/step - loss: 0.0788 - accuracy: 0.9766\n",
      "500/500 [==============================] - 2s 5ms/step - loss: 0.0947 - accuracy: 0.9726\n",
      "334/334 [==============================] - 2s 6ms/step - loss: 0.0519 - accuracy: 0.9860\n",
      "250/250 [==============================] - 1s 6ms/step - loss: 0.0983 - accuracy: 0.9718\n",
      "200/200 [==============================] - 1s 6ms/step - loss: 0.1004 - accuracy: 0.9722\n",
      "167/167 [==============================] - 1s 7ms/step - loss: 0.1028 - accuracy: 0.9698\n",
      "143/143 [==============================] - 1s 8ms/step - loss: 0.1177 - accuracy: 0.9644\n",
      "125/125 [==============================] - 1s 8ms/step - loss: 0.1104 - accuracy: 0.9692\n",
      "112/112 [==============================] - 1s 8ms/step - loss: 0.1167 - accuracy: 0.9716\n",
      "100/100 [==============================] - 1s 9ms/step - loss: 0.1143 - accuracy: 0.9654\n",
      "91/91 [==============================] - 1s 9ms/step - loss: 0.1264 - accuracy: 0.9640\n",
      "84/84 [==============================] - 1s 10ms/step - loss: 0.1346 - accuracy: 0.9628\n",
      "77/77 [==============================] - 1s 11ms/step - loss: 0.1229 - accuracy: 0.9670\n",
      "72/72 [==============================] - 1s 11ms/step - loss: 0.1443 - accuracy: 0.9610\n",
      "67/67 [==============================] - 3s 49ms/step - loss: 0.1430 - accuracy: 0.9584\n",
      "63/63 [==============================] - 1s 13ms/step - loss: 0.1448 - accuracy: 0.9604\n",
      "59/59 [==============================] - 1s 12ms/step - loss: 0.1666 - accuracy: 0.9568\n",
      "56/56 [==============================] - 1s 13ms/step - loss: 0.1714 - accuracy: 0.9538\n",
      "53/53 [==============================] - 1s 13ms/step - loss: 0.1570 - accuracy: 0.9558\n",
      "50/50 [==============================] - 1s 14ms/step - loss: 0.1641 - accuracy: 0.9554\n",
      "48/48 [==============================] - 1s 14ms/step - loss: 0.1841 - accuracy: 0.9496\n",
      "46/46 [==============================] - 1s 15ms/step - loss: 0.1731 - accuracy: 0.9482\n",
      "44/44 [==============================] - 1s 17ms/step - loss: 0.1763 - accuracy: 0.9480\n",
      "42/42 [==============================] - 1s 20ms/step - loss: 0.1885 - accuracy: 0.9474\n",
      "40/40 [==============================] - 1s 19ms/step - loss: 0.2394 - accuracy: 0.9276\n",
      "39/39 [==============================] - 2s 47ms/step - loss: 0.1988 - accuracy: 0.9478\n",
      "38/38 [==============================] - 1s 21ms/step - loss: 0.2044 - accuracy: 0.9394\n",
      "36/36 [==============================] - 1s 22ms/step - loss: 0.2168 - accuracy: 0.9418\n",
      "35/35 [==============================] - 1s 20ms/step - loss: 0.2055 - accuracy: 0.9408\n",
      "34/34 [==============================] - 1s 23ms/step - loss: 0.2171 - accuracy: 0.9390\n",
      "500/500 [==============================] - 2s 5ms/step - loss: 1.0957 - accuracy: 0.6552\n",
      "334/334 [==============================] - 2s 7ms/step - loss: 0.0309 - accuracy: 0.9906\n",
      "250/250 [==============================] - 2s 8ms/step - loss: 0.0537 - accuracy: 0.9854\n",
      "200/200 [==============================] - 1s 7ms/step - loss: 0.0551 - accuracy: 0.9830\n",
      "167/167 [==============================] - 1s 7ms/step - loss: 0.0580 - accuracy: 0.9826\n",
      "143/143 [==============================] - 1s 8ms/step - loss: 0.0693 - accuracy: 0.9804\n",
      "125/125 [==============================] - 1s 8ms/step - loss: 0.0587 - accuracy: 0.9842\n",
      "112/112 [==============================] - 1s 9ms/step - loss: 0.0621 - accuracy: 0.9800\n",
      "100/100 [==============================] - 1s 9ms/step - loss: 0.0719 - accuracy: 0.9800\n",
      "91/91 [==============================] - 1s 10ms/step - loss: 0.0651 - accuracy: 0.9816\n",
      "84/84 [==============================] - 1s 11ms/step - loss: 0.0672 - accuracy: 0.9820\n",
      "77/77 [==============================] - 1s 12ms/step - loss: 0.0693 - accuracy: 0.9790\n",
      "72/72 [==============================] - 1s 12ms/step - loss: 0.0766 - accuracy: 0.9786\n",
      "67/67 [==============================] - 1s 12ms/step - loss: 0.0813 - accuracy: 0.9774\n",
      "63/63 [==============================] - 1s 12ms/step - loss: 0.0867 - accuracy: 0.9752\n",
      "59/59 [==============================] - 1s 13ms/step - loss: 0.0846 - accuracy: 0.9768\n",
      "56/56 [==============================] - 1s 13ms/step - loss: 0.0852 - accuracy: 0.9748\n",
      "53/53 [==============================] - 1s 14ms/step - loss: 0.0989 - accuracy: 0.9724\n",
      "50/50 [==============================] - 1s 14ms/step - loss: 0.0968 - accuracy: 0.9746\n",
      "48/48 [==============================] - 1s 15ms/step - loss: 0.1044 - accuracy: 0.9706\n",
      "46/46 [==============================] - 1s 15ms/step - loss: 0.1038 - accuracy: 0.9728\n",
      "44/44 [==============================] - 1s 16ms/step - loss: 0.0990 - accuracy: 0.9718\n",
      "42/42 [==============================] - 1s 16ms/step - loss: 0.0951 - accuracy: 0.9728\n",
      "40/40 [==============================] - 1s 17ms/step - loss: 0.1253 - accuracy: 0.9664\n",
      "39/39 [==============================] - 1s 18ms/step - loss: 0.1032 - accuracy: 0.9748\n",
      "38/38 [==============================] - 1s 19ms/step - loss: 0.1204 - accuracy: 0.9688\n",
      "36/36 [==============================] - 1s 18ms/step - loss: 0.1137 - accuracy: 0.9672\n",
      "500/500 [==============================] - 1s 3ms/step - loss: 0.4286 - accuracy: 0.9262\n",
      "200/200 [==============================] - 1s 6ms/step - loss: 0.0293 - accuracy: 0.9898\n",
      "167/167 [==============================] - 1s 7ms/step - loss: 0.0362 - accuracy: 0.9884\n",
      "143/143 [==============================] - 1s 8ms/step - loss: 0.0368 - accuracy: 0.9880\n",
      "125/125 [==============================] - 1s 8ms/step - loss: 0.0415 - accuracy: 0.9852\n",
      "112/112 [==============================] - 1s 8ms/step - loss: 0.0373 - accuracy: 0.9894\n",
      "100/100 [==============================] - 1s 9ms/step - loss: 0.0438 - accuracy: 0.9868\n",
      "91/91 [==============================] - 1s 11ms/step - loss: 0.0449 - accuracy: 0.9890\n",
      "84/84 [==============================] - 1s 10ms/step - loss: 0.0472 - accuracy: 0.9872\n",
      "77/77 [==============================] - 1s 11ms/step - loss: 0.0477 - accuracy: 0.9858\n",
      "72/72 [==============================] - 1s 11ms/step - loss: 0.0513 - accuracy: 0.9872\n",
      "67/67 [==============================] - 1s 12ms/step - loss: 0.0513 - accuracy: 0.9854\n",
      "63/63 [==============================] - 1s 12ms/step - loss: 0.0551 - accuracy: 0.9834\n",
      "59/59 [==============================] - 1s 13ms/step - loss: 0.0555 - accuracy: 0.9838\n",
      "56/56 [==============================] - 1s 13ms/step - loss: 0.0535 - accuracy: 0.9840\n",
      "53/53 [==============================] - 1s 13ms/step - loss: 0.0572 - accuracy: 0.9846\n",
      "50/50 [==============================] - 1s 15ms/step - loss: 0.0653 - accuracy: 0.9820\n",
      "48/48 [==============================] - 1s 16ms/step - loss: 0.0623 - accuracy: 0.9820\n",
      "46/46 [==============================] - 1s 16ms/step - loss: 0.0707 - accuracy: 0.9808 0s - loss: 0.0805 - accu\n",
      "44/44 [==============================] - 1s 16ms/step - loss: 0.0657 - accuracy: 0.9794\n"
     ]
    },
    {
     "ename": "KeyboardInterrupt",
     "evalue": "",
     "output_type": "error",
     "traceback": [
      "\u001b[1;31m---------------------------------------------------------------------------\u001b[0m",
      "\u001b[1;31mKeyboardInterrupt\u001b[0m                         Traceback (most recent call last)",
      "\u001b[1;32m<ipython-input-5-9709f60bf159>\u001b[0m in \u001b[0;36m<module>\u001b[1;34m\u001b[0m\n\u001b[0;32m     26\u001b[0m \u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0;32m     27\u001b[0m         \u001b[0mmodels\u001b[0m\u001b[1;33m[\u001b[0m\u001b[0mi\u001b[0m\u001b[1;33m]\u001b[0m\u001b[1;33m.\u001b[0m\u001b[0mfit\u001b[0m\u001b[1;33m(\u001b[0m\u001b[0mdata\u001b[0m\u001b[1;33m.\u001b[0m\u001b[0mreshape\u001b[0m\u001b[1;33m(\u001b[0m\u001b[1;33m-\u001b[0m\u001b[1;36m1\u001b[0m\u001b[1;33m,\u001b[0m \u001b[1;36m32\u001b[0m\u001b[1;33m,\u001b[0m \u001b[1;36m32\u001b[0m\u001b[1;33m,\u001b[0m \u001b[1;36m1\u001b[0m\u001b[1;33m)\u001b[0m\u001b[1;33m,\u001b[0m \u001b[0mans\u001b[0m\u001b[1;33m,\u001b[0m \u001b[0mepochs\u001b[0m\u001b[1;33m=\u001b[0m\u001b[1;36m1\u001b[0m\u001b[1;33m,\u001b[0m \u001b[0mbatch_size\u001b[0m \u001b[1;33m=\u001b[0m \u001b[1;36m5\u001b[0m\u001b[1;33m*\u001b[0m\u001b[1;33m(\u001b[0m\u001b[0mi\u001b[0m\u001b[1;33m+\u001b[0m\u001b[1;36m1\u001b[0m\u001b[1;33m)\u001b[0m\u001b[1;33m,\u001b[0m \u001b[0mcallbacks\u001b[0m\u001b[1;33m=\u001b[0m\u001b[1;33m[\u001b[0m\u001b[0mcheckpoint\u001b[0m\u001b[1;33m]\u001b[0m\u001b[1;33m)\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[1;32m---> 28\u001b[1;33m         \u001b[0manswers\u001b[0m\u001b[1;33m[\u001b[0m\u001b[0mi\u001b[0m\u001b[1;33m]\u001b[0m \u001b[1;33m=\u001b[0m \u001b[0mnp\u001b[0m\u001b[1;33m.\u001b[0m\u001b[0margmax\u001b[0m\u001b[1;33m(\u001b[0m\u001b[0mmodels\u001b[0m\u001b[1;33m[\u001b[0m\u001b[0mi\u001b[0m\u001b[1;33m]\u001b[0m\u001b[1;33m.\u001b[0m\u001b[0mpredict\u001b[0m\u001b[1;33m(\u001b[0m\u001b[0mdata\u001b[0m\u001b[1;33m.\u001b[0m\u001b[0mreshape\u001b[0m\u001b[1;33m(\u001b[0m\u001b[1;33m-\u001b[0m\u001b[1;36m1\u001b[0m\u001b[1;33m,\u001b[0m \u001b[1;36m32\u001b[0m\u001b[1;33m,\u001b[0m \u001b[1;36m32\u001b[0m\u001b[1;33m,\u001b[0m \u001b[1;36m1\u001b[0m\u001b[1;33m)\u001b[0m\u001b[1;33m)\u001b[0m\u001b[1;33m,\u001b[0m \u001b[0maxis\u001b[0m \u001b[1;33m=\u001b[0m \u001b[1;36m1\u001b[0m\u001b[1;33m)\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0m\u001b[0;32m     29\u001b[0m \u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0;32m     30\u001b[0m     \u001b[0manswer\u001b[0m \u001b[1;33m=\u001b[0m \u001b[0manswers\u001b[0m\u001b[1;33m.\u001b[0m\u001b[0mtranspose\u001b[0m\u001b[1;33m(\u001b[0m\u001b[1;33m)\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n",
      "\u001b[1;32m~\\anaconda3_64\\lib\\site-packages\\tensorflow\\python\\keras\\engine\\training.py\u001b[0m in \u001b[0;36m_method_wrapper\u001b[1;34m(self, *args, **kwargs)\u001b[0m\n\u001b[0;32m     86\u001b[0m       raise ValueError('{} is not supported in multi-worker mode.'.format(\n\u001b[0;32m     87\u001b[0m           method.__name__))\n\u001b[1;32m---> 88\u001b[1;33m     \u001b[1;32mreturn\u001b[0m \u001b[0mmethod\u001b[0m\u001b[1;33m(\u001b[0m\u001b[0mself\u001b[0m\u001b[1;33m,\u001b[0m \u001b[1;33m*\u001b[0m\u001b[0margs\u001b[0m\u001b[1;33m,\u001b[0m \u001b[1;33m**\u001b[0m\u001b[0mkwargs\u001b[0m\u001b[1;33m)\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0m\u001b[0;32m     89\u001b[0m \u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0;32m     90\u001b[0m   return tf_decorator.make_decorator(\n",
      "\u001b[1;32m~\\anaconda3_64\\lib\\site-packages\\tensorflow\\python\\keras\\engine\\training.py\u001b[0m in \u001b[0;36mpredict\u001b[1;34m(self, x, batch_size, verbose, steps, callbacks, max_queue_size, workers, use_multiprocessing)\u001b[0m\n\u001b[0;32m   1238\u001b[0m     \u001b[1;32mwith\u001b[0m \u001b[0mself\u001b[0m\u001b[1;33m.\u001b[0m\u001b[0mdistribute_strategy\u001b[0m\u001b[1;33m.\u001b[0m\u001b[0mscope\u001b[0m\u001b[1;33m(\u001b[0m\u001b[1;33m)\u001b[0m\u001b[1;33m:\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0;32m   1239\u001b[0m       \u001b[1;31m# Creates a `tf.data.Dataset` and handles batch and epoch iteration.\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[1;32m-> 1240\u001b[1;33m       data_handler = data_adapter.DataHandler(\n\u001b[0m\u001b[0;32m   1241\u001b[0m           \u001b[0mx\u001b[0m\u001b[1;33m=\u001b[0m\u001b[0mx\u001b[0m\u001b[1;33m,\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0;32m   1242\u001b[0m           \u001b[0mbatch_size\u001b[0m\u001b[1;33m=\u001b[0m\u001b[0mbatch_size\u001b[0m\u001b[1;33m,\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n",
      "\u001b[1;32m~\\anaconda3_64\\lib\\site-packages\\tensorflow\\python\\keras\\engine\\data_adapter.py\u001b[0m in \u001b[0;36m__init__\u001b[1;34m(self, x, y, sample_weight, batch_size, steps_per_epoch, initial_epoch, epochs, shuffle, class_weight, max_queue_size, workers, use_multiprocessing, model)\u001b[0m\n\u001b[0;32m   1098\u001b[0m \u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0;32m   1099\u001b[0m     \u001b[0madapter_cls\u001b[0m \u001b[1;33m=\u001b[0m \u001b[0mselect_data_adapter\u001b[0m\u001b[1;33m(\u001b[0m\u001b[0mx\u001b[0m\u001b[1;33m,\u001b[0m \u001b[0my\u001b[0m\u001b[1;33m)\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[1;32m-> 1100\u001b[1;33m     self._adapter = adapter_cls(\n\u001b[0m\u001b[0;32m   1101\u001b[0m         \u001b[0mx\u001b[0m\u001b[1;33m,\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0;32m   1102\u001b[0m         \u001b[0my\u001b[0m\u001b[1;33m,\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n",
      "\u001b[1;32m~\\anaconda3_64\\lib\\site-packages\\tensorflow\\python\\keras\\engine\\data_adapter.py\u001b[0m in \u001b[0;36m__init__\u001b[1;34m(self, x, y, sample_weights, sample_weight_modes, batch_size, epochs, steps, shuffle, **kwargs)\u001b[0m\n\u001b[0;32m    263\u001b[0m                **kwargs):\n\u001b[0;32m    264\u001b[0m     \u001b[0msuper\u001b[0m\u001b[1;33m(\u001b[0m\u001b[0mTensorLikeDataAdapter\u001b[0m\u001b[1;33m,\u001b[0m \u001b[0mself\u001b[0m\u001b[1;33m)\u001b[0m\u001b[1;33m.\u001b[0m\u001b[0m__init__\u001b[0m\u001b[1;33m(\u001b[0m\u001b[0mx\u001b[0m\u001b[1;33m,\u001b[0m \u001b[0my\u001b[0m\u001b[1;33m,\u001b[0m \u001b[1;33m**\u001b[0m\u001b[0mkwargs\u001b[0m\u001b[1;33m)\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[1;32m--> 265\u001b[1;33m     \u001b[0mx\u001b[0m\u001b[1;33m,\u001b[0m \u001b[0my\u001b[0m\u001b[1;33m,\u001b[0m \u001b[0msample_weights\u001b[0m \u001b[1;33m=\u001b[0m \u001b[0m_process_tensorlike\u001b[0m\u001b[1;33m(\u001b[0m\u001b[1;33m(\u001b[0m\u001b[0mx\u001b[0m\u001b[1;33m,\u001b[0m \u001b[0my\u001b[0m\u001b[1;33m,\u001b[0m \u001b[0msample_weights\u001b[0m\u001b[1;33m)\u001b[0m\u001b[1;33m)\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0m\u001b[0;32m    266\u001b[0m     sample_weight_modes = broadcast_sample_weight_modes(\n\u001b[0;32m    267\u001b[0m         sample_weights, sample_weight_modes)\n",
      "\u001b[1;32m~\\anaconda3_64\\lib\\site-packages\\tensorflow\\python\\keras\\engine\\data_adapter.py\u001b[0m in \u001b[0;36m_process_tensorlike\u001b[1;34m(inputs)\u001b[0m\n\u001b[0;32m   1011\u001b[0m     \u001b[1;32mreturn\u001b[0m \u001b[0mx\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0;32m   1012\u001b[0m \u001b[1;33m\u001b[0m\u001b[0m\n\u001b[1;32m-> 1013\u001b[1;33m   \u001b[0minputs\u001b[0m \u001b[1;33m=\u001b[0m \u001b[0mnest\u001b[0m\u001b[1;33m.\u001b[0m\u001b[0mmap_structure\u001b[0m\u001b[1;33m(\u001b[0m\u001b[0m_convert_numpy_and_scipy\u001b[0m\u001b[1;33m,\u001b[0m \u001b[0minputs\u001b[0m\u001b[1;33m)\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0m\u001b[0;32m   1014\u001b[0m   \u001b[1;32mreturn\u001b[0m \u001b[0mnest\u001b[0m\u001b[1;33m.\u001b[0m\u001b[0m_list_to_tuple\u001b[0m\u001b[1;33m(\u001b[0m\u001b[0minputs\u001b[0m\u001b[1;33m)\u001b[0m  \u001b[1;31m# pylint: disable=protected-access\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0;32m   1015\u001b[0m \u001b[1;33m\u001b[0m\u001b[0m\n",
      "\u001b[1;32m~\\anaconda3_64\\lib\\site-packages\\tensorflow\\python\\util\\nest.py\u001b[0m in \u001b[0;36mmap_structure\u001b[1;34m(func, *structure, **kwargs)\u001b[0m\n\u001b[0;32m    615\u001b[0m \u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0;32m    616\u001b[0m   return pack_sequence_as(\n\u001b[1;32m--> 617\u001b[1;33m       \u001b[0mstructure\u001b[0m\u001b[1;33m[\u001b[0m\u001b[1;36m0\u001b[0m\u001b[1;33m]\u001b[0m\u001b[1;33m,\u001b[0m \u001b[1;33m[\u001b[0m\u001b[0mfunc\u001b[0m\u001b[1;33m(\u001b[0m\u001b[1;33m*\u001b[0m\u001b[0mx\u001b[0m\u001b[1;33m)\u001b[0m \u001b[1;32mfor\u001b[0m \u001b[0mx\u001b[0m \u001b[1;32min\u001b[0m \u001b[0mentries\u001b[0m\u001b[1;33m]\u001b[0m\u001b[1;33m,\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0m\u001b[0;32m    618\u001b[0m       expand_composites=expand_composites)\n\u001b[0;32m    619\u001b[0m \u001b[1;33m\u001b[0m\u001b[0m\n",
      "\u001b[1;32m~\\anaconda3_64\\lib\\site-packages\\tensorflow\\python\\util\\nest.py\u001b[0m in \u001b[0;36m<listcomp>\u001b[1;34m(.0)\u001b[0m\n\u001b[0;32m    615\u001b[0m \u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0;32m    616\u001b[0m   return pack_sequence_as(\n\u001b[1;32m--> 617\u001b[1;33m       \u001b[0mstructure\u001b[0m\u001b[1;33m[\u001b[0m\u001b[1;36m0\u001b[0m\u001b[1;33m]\u001b[0m\u001b[1;33m,\u001b[0m \u001b[1;33m[\u001b[0m\u001b[0mfunc\u001b[0m\u001b[1;33m(\u001b[0m\u001b[1;33m*\u001b[0m\u001b[0mx\u001b[0m\u001b[1;33m)\u001b[0m \u001b[1;32mfor\u001b[0m \u001b[0mx\u001b[0m \u001b[1;32min\u001b[0m \u001b[0mentries\u001b[0m\u001b[1;33m]\u001b[0m\u001b[1;33m,\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0m\u001b[0;32m    618\u001b[0m       expand_composites=expand_composites)\n\u001b[0;32m    619\u001b[0m \u001b[1;33m\u001b[0m\u001b[0m\n",
      "\u001b[1;32m~\\anaconda3_64\\lib\\site-packages\\tensorflow\\python\\keras\\engine\\data_adapter.py\u001b[0m in \u001b[0;36m_convert_numpy_and_scipy\u001b[1;34m(x)\u001b[0m\n\u001b[0;32m   1006\u001b[0m       \u001b[1;32mif\u001b[0m \u001b[0missubclass\u001b[0m\u001b[1;33m(\u001b[0m\u001b[0mx\u001b[0m\u001b[1;33m.\u001b[0m\u001b[0mdtype\u001b[0m\u001b[1;33m.\u001b[0m\u001b[0mtype\u001b[0m\u001b[1;33m,\u001b[0m \u001b[0mnp\u001b[0m\u001b[1;33m.\u001b[0m\u001b[0mfloating\u001b[0m\u001b[1;33m)\u001b[0m\u001b[1;33m:\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0;32m   1007\u001b[0m         \u001b[0mdtype\u001b[0m \u001b[1;33m=\u001b[0m \u001b[0mbackend\u001b[0m\u001b[1;33m.\u001b[0m\u001b[0mfloatx\u001b[0m\u001b[1;33m(\u001b[0m\u001b[1;33m)\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[1;32m-> 1008\u001b[1;33m       \u001b[1;32mreturn\u001b[0m \u001b[0mops\u001b[0m\u001b[1;33m.\u001b[0m\u001b[0mconvert_to_tensor\u001b[0m\u001b[1;33m(\u001b[0m\u001b[0mx\u001b[0m\u001b[1;33m,\u001b[0m \u001b[0mdtype\u001b[0m\u001b[1;33m=\u001b[0m\u001b[0mdtype\u001b[0m\u001b[1;33m)\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0m\u001b[0;32m   1009\u001b[0m     \u001b[1;32melif\u001b[0m \u001b[0mscipy_sparse\u001b[0m \u001b[1;32mand\u001b[0m \u001b[0mscipy_sparse\u001b[0m\u001b[1;33m.\u001b[0m\u001b[0missparse\u001b[0m\u001b[1;33m(\u001b[0m\u001b[0mx\u001b[0m\u001b[1;33m)\u001b[0m\u001b[1;33m:\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0;32m   1010\u001b[0m       \u001b[1;32mreturn\u001b[0m \u001b[0m_scipy_sparse_to_sparse_tensor\u001b[0m\u001b[1;33m(\u001b[0m\u001b[0mx\u001b[0m\u001b[1;33m)\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n",
      "\u001b[1;32m~\\anaconda3_64\\lib\\site-packages\\tensorflow\\python\\framework\\ops.py\u001b[0m in \u001b[0;36mconvert_to_tensor\u001b[1;34m(value, dtype, name, as_ref, preferred_dtype, dtype_hint, ctx, accepted_result_types)\u001b[0m\n\u001b[0;32m   1339\u001b[0m \u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0;32m   1340\u001b[0m     \u001b[1;32mif\u001b[0m \u001b[0mret\u001b[0m \u001b[1;32mis\u001b[0m \u001b[1;32mNone\u001b[0m\u001b[1;33m:\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[1;32m-> 1341\u001b[1;33m       \u001b[0mret\u001b[0m \u001b[1;33m=\u001b[0m \u001b[0mconversion_func\u001b[0m\u001b[1;33m(\u001b[0m\u001b[0mvalue\u001b[0m\u001b[1;33m,\u001b[0m \u001b[0mdtype\u001b[0m\u001b[1;33m=\u001b[0m\u001b[0mdtype\u001b[0m\u001b[1;33m,\u001b[0m \u001b[0mname\u001b[0m\u001b[1;33m=\u001b[0m\u001b[0mname\u001b[0m\u001b[1;33m,\u001b[0m \u001b[0mas_ref\u001b[0m\u001b[1;33m=\u001b[0m\u001b[0mas_ref\u001b[0m\u001b[1;33m)\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0m\u001b[0;32m   1342\u001b[0m \u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0;32m   1343\u001b[0m     \u001b[1;32mif\u001b[0m \u001b[0mret\u001b[0m \u001b[1;32mis\u001b[0m \u001b[0mNotImplemented\u001b[0m\u001b[1;33m:\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n",
      "\u001b[1;32m~\\anaconda3_64\\lib\\site-packages\\tensorflow\\python\\framework\\tensor_conversion_registry.py\u001b[0m in \u001b[0;36m_default_conversion_function\u001b[1;34m(***failed resolving arguments***)\u001b[0m\n\u001b[0;32m     50\u001b[0m \u001b[1;32mdef\u001b[0m \u001b[0m_default_conversion_function\u001b[0m\u001b[1;33m(\u001b[0m\u001b[0mvalue\u001b[0m\u001b[1;33m,\u001b[0m \u001b[0mdtype\u001b[0m\u001b[1;33m,\u001b[0m \u001b[0mname\u001b[0m\u001b[1;33m,\u001b[0m \u001b[0mas_ref\u001b[0m\u001b[1;33m)\u001b[0m\u001b[1;33m:\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0;32m     51\u001b[0m   \u001b[1;32mdel\u001b[0m \u001b[0mas_ref\u001b[0m  \u001b[1;31m# Unused.\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[1;32m---> 52\u001b[1;33m   \u001b[1;32mreturn\u001b[0m \u001b[0mconstant_op\u001b[0m\u001b[1;33m.\u001b[0m\u001b[0mconstant\u001b[0m\u001b[1;33m(\u001b[0m\u001b[0mvalue\u001b[0m\u001b[1;33m,\u001b[0m \u001b[0mdtype\u001b[0m\u001b[1;33m,\u001b[0m \u001b[0mname\u001b[0m\u001b[1;33m=\u001b[0m\u001b[0mname\u001b[0m\u001b[1;33m)\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0m\u001b[0;32m     53\u001b[0m \u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0;32m     54\u001b[0m \u001b[1;33m\u001b[0m\u001b[0m\n",
      "\u001b[1;32m~\\anaconda3_64\\lib\\site-packages\\tensorflow\\python\\framework\\constant_op.py\u001b[0m in \u001b[0;36mconstant\u001b[1;34m(value, dtype, shape, name)\u001b[0m\n\u001b[0;32m    259\u001b[0m     \u001b[0mValueError\u001b[0m\u001b[1;33m:\u001b[0m \u001b[1;32mif\u001b[0m \u001b[0mcalled\u001b[0m \u001b[0mon\u001b[0m \u001b[0ma\u001b[0m \u001b[0msymbolic\u001b[0m \u001b[0mtensor\u001b[0m\u001b[1;33m.\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0;32m    260\u001b[0m   \"\"\"\n\u001b[1;32m--> 261\u001b[1;33m   return _constant_impl(value, dtype, shape, name, verify_shape=False,\n\u001b[0m\u001b[0;32m    262\u001b[0m                         allow_broadcast=True)\n\u001b[0;32m    263\u001b[0m \u001b[1;33m\u001b[0m\u001b[0m\n",
      "\u001b[1;32m~\\anaconda3_64\\lib\\site-packages\\tensorflow\\python\\framework\\constant_op.py\u001b[0m in \u001b[0;36m_constant_impl\u001b[1;34m(value, dtype, shape, name, verify_shape, allow_broadcast)\u001b[0m\n\u001b[0;32m    268\u001b[0m   \u001b[0mctx\u001b[0m \u001b[1;33m=\u001b[0m \u001b[0mcontext\u001b[0m\u001b[1;33m.\u001b[0m\u001b[0mcontext\u001b[0m\u001b[1;33m(\u001b[0m\u001b[1;33m)\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0;32m    269\u001b[0m   \u001b[1;32mif\u001b[0m \u001b[0mctx\u001b[0m\u001b[1;33m.\u001b[0m\u001b[0mexecuting_eagerly\u001b[0m\u001b[1;33m(\u001b[0m\u001b[1;33m)\u001b[0m\u001b[1;33m:\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[1;32m--> 270\u001b[1;33m     \u001b[0mt\u001b[0m \u001b[1;33m=\u001b[0m \u001b[0mconvert_to_eager_tensor\u001b[0m\u001b[1;33m(\u001b[0m\u001b[0mvalue\u001b[0m\u001b[1;33m,\u001b[0m \u001b[0mctx\u001b[0m\u001b[1;33m,\u001b[0m \u001b[0mdtype\u001b[0m\u001b[1;33m)\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0m\u001b[0;32m    271\u001b[0m     \u001b[1;32mif\u001b[0m \u001b[0mshape\u001b[0m \u001b[1;32mis\u001b[0m \u001b[1;32mNone\u001b[0m\u001b[1;33m:\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0;32m    272\u001b[0m       \u001b[1;32mreturn\u001b[0m \u001b[0mt\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n",
      "\u001b[1;32m~\\anaconda3_64\\lib\\site-packages\\tensorflow\\python\\framework\\constant_op.py\u001b[0m in \u001b[0;36mconvert_to_eager_tensor\u001b[1;34m(value, ctx, dtype)\u001b[0m\n\u001b[0;32m     94\u001b[0m       \u001b[0mdtype\u001b[0m \u001b[1;33m=\u001b[0m \u001b[0mdtypes\u001b[0m\u001b[1;33m.\u001b[0m\u001b[0mas_dtype\u001b[0m\u001b[1;33m(\u001b[0m\u001b[0mdtype\u001b[0m\u001b[1;33m)\u001b[0m\u001b[1;33m.\u001b[0m\u001b[0mas_datatype_enum\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0;32m     95\u001b[0m   \u001b[0mctx\u001b[0m\u001b[1;33m.\u001b[0m\u001b[0mensure_initialized\u001b[0m\u001b[1;33m(\u001b[0m\u001b[1;33m)\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[1;32m---> 96\u001b[1;33m   \u001b[1;32mreturn\u001b[0m \u001b[0mops\u001b[0m\u001b[1;33m.\u001b[0m\u001b[0mEagerTensor\u001b[0m\u001b[1;33m(\u001b[0m\u001b[0mvalue\u001b[0m\u001b[1;33m,\u001b[0m \u001b[0mctx\u001b[0m\u001b[1;33m.\u001b[0m\u001b[0mdevice_name\u001b[0m\u001b[1;33m,\u001b[0m \u001b[0mdtype\u001b[0m\u001b[1;33m)\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0m\u001b[0;32m     97\u001b[0m \u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0;32m     98\u001b[0m \u001b[1;33m\u001b[0m\u001b[0m\n",
      "\u001b[1;31mKeyboardInterrupt\u001b[0m: "
     ]
    }
   ],
   "source": [
    "answers = np.ndarray((num_mod, ans.shape[0]))\n",
    "\n",
    "model = tf.keras.models.Sequential([\n",
    "    tf.keras.layers.Conv1D(input_shape=(num_mod,1), filters=30, kernel_size=10, padding='same', activation='softmax'),\n",
    "    tf.keras.layers.MaxPool1D(pool_size=2),\n",
    "    tf.keras.layers.Flatten(),\n",
    "    tf.keras.layers.Dense(num_mod*3, activation=tf.nn.relu),\n",
    "    tf.keras.layers.Dense(num_classes, activation=tf.nn.softmax)\n",
    "])\n",
    "\n",
    "\n",
    "model.compile(\n",
    "    optimizer='adam',\n",
    "    loss='sparse_categorical_crossentropy',\n",
    "    metrics=['accuracy'])\n",
    "\n",
    "weights_file = 'weights.hdf5'\n",
    "checkpoint = tf.keras.callbacks.ModelCheckpoint(weights_file, monitor='acc')\n",
    "\n",
    "for j in range(5):\n",
    "    for i in range(2*j, num_mod-2*j):\n",
    "        models[i].compile(\n",
    "        optimizer='adam',\n",
    "        loss='sparse_categorical_crossentropy',\n",
    "        metrics=['accuracy']) \n",
    "    \n",
    "        models[i].fit(data.reshape(-1, 32, 32, 1), ans, epochs=1, batch_size = 5*(i+1), callbacks=[checkpoint])\n",
    "        answers[i] = np.argmax(models[i].predict(data.reshape(-1, 32, 32, 1)), axis = 1)\n",
    "    \n",
    "    answer = answers.transpose()\n",
    "    model.fit(answer.reshape(-1, num_mod, 1), ans, epochs=1, batch_size = 10, callbacks=[checkpoint])\n",
    "\n",
    "d_test = np.ndarray((num_mod, result_test.shape[0]))\n",
    "for i in range(num_mod):\n",
    "    d_test[i] = np.argmax(models[i].predict(Y_test.reshape(-1, 32, 32, 1)), axis = 1)\n",
    "    \n",
    "d_test = d_test.transpose()\n",
    "most, mostcc = scipy.stats.mode(d_test, axis=1)\n",
    "\n",
    "mist = 0\n",
    "most.reshape(most.shape[0],)\n",
    "for i in range(most.shape[0]):\n",
    "    if most[i] != result_test[i]:\n",
    "        mist += 1/most.shape[0]\n",
    "print(mist)\n",
    "\n",
    "model.evaluate(d_test.reshape(-1, num_mod, 1), result_test)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Epoch 1/3\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "ERROR:root:Internal Python error in the inspect module.\n",
      "Below is the traceback from this internal error.\n",
      "\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Traceback (most recent call last):\n",
      "  File \"C:\\Users\\nikit\\anaconda3_64\\lib\\site-packages\\IPython\\core\\interactiveshell.py\", line 3418, in run_code\n",
      "    exec(code_obj, self.user_global_ns, self.user_ns)\n",
      "  File \"<ipython-input-5-4c3041d4c086>\", line 12, in <module>\n",
      "    models[i].fit(data.reshape(-1, 32, 32, 1), ans, epochs=3, batch_size = 3*(i+1), callbacks=[checkpoint])\n",
      "  File \"C:\\Users\\nikit\\anaconda3_64\\lib\\site-packages\\tensorflow\\python\\keras\\engine\\training.py\", line 66, in _method_wrapper\n",
      "    return method(self, *args, **kwargs)\n",
      "  File \"C:\\Users\\nikit\\anaconda3_64\\lib\\site-packages\\tensorflow\\python\\keras\\engine\\training.py\", line 848, in fit\n",
      "    tmp_logs = train_function(iterator)\n",
      "  File \"C:\\Users\\nikit\\anaconda3_64\\lib\\site-packages\\tensorflow\\python\\eager\\def_function.py\", line 580, in __call__\n",
      "    result = self._call(*args, **kwds)\n",
      "  File \"C:\\Users\\nikit\\anaconda3_64\\lib\\site-packages\\tensorflow\\python\\eager\\def_function.py\", line 644, in _call\n",
      "    return self._stateless_fn(*args, **kwds)\n",
      "  File \"C:\\Users\\nikit\\anaconda3_64\\lib\\site-packages\\tensorflow\\python\\eager\\function.py\", line 2420, in __call__\n",
      "    return graph_function._filtered_call(args, kwargs)  # pylint: disable=protected-access\n",
      "  File \"C:\\Users\\nikit\\anaconda3_64\\lib\\site-packages\\tensorflow\\python\\eager\\function.py\", line 1661, in _filtered_call\n",
      "    return self._call_flat(\n",
      "  File \"C:\\Users\\nikit\\anaconda3_64\\lib\\site-packages\\tensorflow\\python\\eager\\function.py\", line 1745, in _call_flat\n",
      "    return self._build_call_outputs(self._inference_function.call(\n",
      "  File \"C:\\Users\\nikit\\anaconda3_64\\lib\\site-packages\\tensorflow\\python\\eager\\function.py\", line 593, in call\n",
      "    outputs = execute.execute(\n",
      "  File \"C:\\Users\\nikit\\anaconda3_64\\lib\\site-packages\\tensorflow\\python\\eager\\execute.py\", line 59, in quick_execute\n",
      "    tensors = pywrap_tfe.TFE_Py_Execute(ctx._handle, device_name, op_name,\n",
      "tensorflow.python.framework.errors_impl.UnknownError:  Failed to get convolution algorithm. This is probably because cuDNN failed to initialize, so try looking to see if a warning log message was printed above.\n",
      "\t [[node sequential/conv2d/Conv2D (defined at <ipython-input-5-4c3041d4c086>:12) ]] [Op:__inference_train_function_4164]\n",
      "\n",
      "Function call stack:\n",
      "train_function\n",
      "\n",
      "\n",
      "During handling of the above exception, another exception occurred:\n",
      "\n",
      "Traceback (most recent call last):\n",
      "  File \"C:\\Users\\nikit\\anaconda3_64\\lib\\site-packages\\IPython\\core\\interactiveshell.py\", line 2045, in showtraceback\n",
      "    stb = value._render_traceback_()\n",
      "AttributeError: 'UnknownError' object has no attribute '_render_traceback_'\n",
      "\n",
      "During handling of the above exception, another exception occurred:\n",
      "\n",
      "Traceback (most recent call last):\n",
      "  File \"C:\\Users\\nikit\\anaconda3_64\\lib\\site-packages\\IPython\\core\\ultratb.py\", line 1170, in get_records\n",
      "    return _fixed_getinnerframes(etb, number_of_lines_of_context, tb_offset)\n",
      "  File \"C:\\Users\\nikit\\anaconda3_64\\lib\\site-packages\\IPython\\core\\ultratb.py\", line 316, in wrapped\n",
      "    return f(*args, **kwargs)\n",
      "  File \"C:\\Users\\nikit\\anaconda3_64\\lib\\site-packages\\IPython\\core\\ultratb.py\", line 350, in _fixed_getinnerframes\n",
      "    records = fix_frame_records_filenames(inspect.getinnerframes(etb, context))\n",
      "  File \"C:\\Users\\nikit\\anaconda3_64\\lib\\inspect.py\", line 1503, in getinnerframes\n",
      "    frameinfo = (tb.tb_frame,) + getframeinfo(tb, context)\n",
      "  File \"C:\\Users\\nikit\\anaconda3_64\\lib\\inspect.py\", line 1461, in getframeinfo\n",
      "    filename = getsourcefile(frame) or getfile(frame)\n",
      "  File \"C:\\Users\\nikit\\anaconda3_64\\lib\\inspect.py\", line 708, in getsourcefile\n",
      "    if getattr(getmodule(object, filename), '__loader__', None) is not None:\n",
      "  File \"C:\\Users\\nikit\\anaconda3_64\\lib\\inspect.py\", line 744, in getmodule\n",
      "    for modname, module in sys.modules.copy().items():\n",
      "MemoryError\n"
     ]
    },
    {
     "ename": "TypeError",
     "evalue": "object of type 'NoneType' has no len()",
     "output_type": "error",
     "traceback": [
      "\u001b[1;31m---------------------------------------------------------------------------\u001b[0m",
      "\u001b[1;31mUnknownError\u001b[0m                              Traceback (most recent call last)",
      "    \u001b[1;31m[... skipping hidden 1 frame]\u001b[0m\n",
      "\u001b[1;32m<ipython-input-5-4c3041d4c086>\u001b[0m in \u001b[0;36m<module>\u001b[1;34m\u001b[0m\n\u001b[0;32m     11\u001b[0m \u001b[1;33m\u001b[0m\u001b[0m\n\u001b[1;32m---> 12\u001b[1;33m     \u001b[0mmodels\u001b[0m\u001b[1;33m[\u001b[0m\u001b[0mi\u001b[0m\u001b[1;33m]\u001b[0m\u001b[1;33m.\u001b[0m\u001b[0mfit\u001b[0m\u001b[1;33m(\u001b[0m\u001b[0mdata\u001b[0m\u001b[1;33m.\u001b[0m\u001b[0mreshape\u001b[0m\u001b[1;33m(\u001b[0m\u001b[1;33m-\u001b[0m\u001b[1;36m1\u001b[0m\u001b[1;33m,\u001b[0m \u001b[1;36m32\u001b[0m\u001b[1;33m,\u001b[0m \u001b[1;36m32\u001b[0m\u001b[1;33m,\u001b[0m \u001b[1;36m1\u001b[0m\u001b[1;33m)\u001b[0m\u001b[1;33m,\u001b[0m \u001b[0mans\u001b[0m\u001b[1;33m,\u001b[0m \u001b[0mepochs\u001b[0m\u001b[1;33m=\u001b[0m\u001b[1;36m3\u001b[0m\u001b[1;33m,\u001b[0m \u001b[0mbatch_size\u001b[0m \u001b[1;33m=\u001b[0m \u001b[1;36m3\u001b[0m\u001b[1;33m*\u001b[0m\u001b[1;33m(\u001b[0m\u001b[0mi\u001b[0m\u001b[1;33m+\u001b[0m\u001b[1;36m1\u001b[0m\u001b[1;33m)\u001b[0m\u001b[1;33m,\u001b[0m \u001b[0mcallbacks\u001b[0m\u001b[1;33m=\u001b[0m\u001b[1;33m[\u001b[0m\u001b[0mcheckpoint\u001b[0m\u001b[1;33m]\u001b[0m\u001b[1;33m)\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0m\u001b[0;32m     13\u001b[0m     \u001b[0manswers\u001b[0m\u001b[1;33m[\u001b[0m\u001b[0mi\u001b[0m\u001b[1;33m]\u001b[0m \u001b[1;33m=\u001b[0m \u001b[0mnp\u001b[0m\u001b[1;33m.\u001b[0m\u001b[0margmax\u001b[0m\u001b[1;33m(\u001b[0m\u001b[0mmodels\u001b[0m\u001b[1;33m[\u001b[0m\u001b[0mi\u001b[0m\u001b[1;33m]\u001b[0m\u001b[1;33m.\u001b[0m\u001b[0mpredict\u001b[0m\u001b[1;33m(\u001b[0m\u001b[0mmeta_data\u001b[0m\u001b[1;33m.\u001b[0m\u001b[0mreshape\u001b[0m\u001b[1;33m(\u001b[0m\u001b[1;33m-\u001b[0m\u001b[1;36m1\u001b[0m\u001b[1;33m,\u001b[0m \u001b[1;36m32\u001b[0m\u001b[1;33m,\u001b[0m \u001b[1;36m32\u001b[0m\u001b[1;33m,\u001b[0m \u001b[1;36m1\u001b[0m\u001b[1;33m)\u001b[0m\u001b[1;33m)\u001b[0m\u001b[1;33m,\u001b[0m \u001b[0maxis\u001b[0m \u001b[1;33m=\u001b[0m \u001b[1;36m1\u001b[0m\u001b[1;33m)\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n",
      "\u001b[1;32m~\\anaconda3_64\\lib\\site-packages\\tensorflow\\python\\keras\\engine\\training.py\u001b[0m in \u001b[0;36m_method_wrapper\u001b[1;34m(self, *args, **kwargs)\u001b[0m\n\u001b[0;32m     65\u001b[0m     \u001b[1;32mif\u001b[0m \u001b[1;32mnot\u001b[0m \u001b[0mself\u001b[0m\u001b[1;33m.\u001b[0m\u001b[0m_in_multi_worker_mode\u001b[0m\u001b[1;33m(\u001b[0m\u001b[1;33m)\u001b[0m\u001b[1;33m:\u001b[0m  \u001b[1;31m# pylint: disable=protected-access\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[1;32m---> 66\u001b[1;33m       \u001b[1;32mreturn\u001b[0m \u001b[0mmethod\u001b[0m\u001b[1;33m(\u001b[0m\u001b[0mself\u001b[0m\u001b[1;33m,\u001b[0m \u001b[1;33m*\u001b[0m\u001b[0margs\u001b[0m\u001b[1;33m,\u001b[0m \u001b[1;33m**\u001b[0m\u001b[0mkwargs\u001b[0m\u001b[1;33m)\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0m\u001b[0;32m     67\u001b[0m \u001b[1;33m\u001b[0m\u001b[0m\n",
      "\u001b[1;32m~\\anaconda3_64\\lib\\site-packages\\tensorflow\\python\\keras\\engine\\training.py\u001b[0m in \u001b[0;36mfit\u001b[1;34m(self, x, y, batch_size, epochs, verbose, callbacks, validation_split, validation_data, shuffle, class_weight, sample_weight, initial_epoch, steps_per_epoch, validation_steps, validation_batch_size, validation_freq, max_queue_size, workers, use_multiprocessing)\u001b[0m\n\u001b[0;32m    847\u001b[0m               \u001b[0mcallbacks\u001b[0m\u001b[1;33m.\u001b[0m\u001b[0mon_train_batch_begin\u001b[0m\u001b[1;33m(\u001b[0m\u001b[0mstep\u001b[0m\u001b[1;33m)\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[1;32m--> 848\u001b[1;33m               \u001b[0mtmp_logs\u001b[0m \u001b[1;33m=\u001b[0m \u001b[0mtrain_function\u001b[0m\u001b[1;33m(\u001b[0m\u001b[0miterator\u001b[0m\u001b[1;33m)\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0m\u001b[0;32m    849\u001b[0m               \u001b[1;31m# Catch OutOfRangeError for Datasets of unknown size.\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n",
      "\u001b[1;32m~\\anaconda3_64\\lib\\site-packages\\tensorflow\\python\\eager\\def_function.py\u001b[0m in \u001b[0;36m__call__\u001b[1;34m(self, *args, **kwds)\u001b[0m\n\u001b[0;32m    579\u001b[0m     \u001b[1;32melse\u001b[0m\u001b[1;33m:\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[1;32m--> 580\u001b[1;33m       \u001b[0mresult\u001b[0m \u001b[1;33m=\u001b[0m \u001b[0mself\u001b[0m\u001b[1;33m.\u001b[0m\u001b[0m_call\u001b[0m\u001b[1;33m(\u001b[0m\u001b[1;33m*\u001b[0m\u001b[0margs\u001b[0m\u001b[1;33m,\u001b[0m \u001b[1;33m**\u001b[0m\u001b[0mkwds\u001b[0m\u001b[1;33m)\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0m\u001b[0;32m    581\u001b[0m \u001b[1;33m\u001b[0m\u001b[0m\n",
      "\u001b[1;32m~\\anaconda3_64\\lib\\site-packages\\tensorflow\\python\\eager\\def_function.py\u001b[0m in \u001b[0;36m_call\u001b[1;34m(self, *args, **kwds)\u001b[0m\n\u001b[0;32m    643\u001b[0m         \u001b[1;31m# stateless function.\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[1;32m--> 644\u001b[1;33m         \u001b[1;32mreturn\u001b[0m \u001b[0mself\u001b[0m\u001b[1;33m.\u001b[0m\u001b[0m_stateless_fn\u001b[0m\u001b[1;33m(\u001b[0m\u001b[1;33m*\u001b[0m\u001b[0margs\u001b[0m\u001b[1;33m,\u001b[0m \u001b[1;33m**\u001b[0m\u001b[0mkwds\u001b[0m\u001b[1;33m)\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0m\u001b[0;32m    645\u001b[0m     \u001b[1;32melse\u001b[0m\u001b[1;33m:\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n",
      "\u001b[1;32m~\\anaconda3_64\\lib\\site-packages\\tensorflow\\python\\eager\\function.py\u001b[0m in \u001b[0;36m__call__\u001b[1;34m(self, *args, **kwargs)\u001b[0m\n\u001b[0;32m   2419\u001b[0m       \u001b[0mgraph_function\u001b[0m\u001b[1;33m,\u001b[0m \u001b[0margs\u001b[0m\u001b[1;33m,\u001b[0m \u001b[0mkwargs\u001b[0m \u001b[1;33m=\u001b[0m \u001b[0mself\u001b[0m\u001b[1;33m.\u001b[0m\u001b[0m_maybe_define_function\u001b[0m\u001b[1;33m(\u001b[0m\u001b[0margs\u001b[0m\u001b[1;33m,\u001b[0m \u001b[0mkwargs\u001b[0m\u001b[1;33m)\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[1;32m-> 2420\u001b[1;33m     \u001b[1;32mreturn\u001b[0m \u001b[0mgraph_function\u001b[0m\u001b[1;33m.\u001b[0m\u001b[0m_filtered_call\u001b[0m\u001b[1;33m(\u001b[0m\u001b[0margs\u001b[0m\u001b[1;33m,\u001b[0m \u001b[0mkwargs\u001b[0m\u001b[1;33m)\u001b[0m  \u001b[1;31m# pylint: disable=protected-access\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0m\u001b[0;32m   2421\u001b[0m \u001b[1;33m\u001b[0m\u001b[0m\n",
      "\u001b[1;32m~\\anaconda3_64\\lib\\site-packages\\tensorflow\\python\\eager\\function.py\u001b[0m in \u001b[0;36m_filtered_call\u001b[1;34m(self, args, kwargs)\u001b[0m\n\u001b[0;32m   1660\u001b[0m     \"\"\"\n\u001b[1;32m-> 1661\u001b[1;33m     return self._call_flat(\n\u001b[0m\u001b[0;32m   1662\u001b[0m         (t for t in nest.flatten((args, kwargs), expand_composites=True)\n",
      "\u001b[1;32m~\\anaconda3_64\\lib\\site-packages\\tensorflow\\python\\eager\\function.py\u001b[0m in \u001b[0;36m_call_flat\u001b[1;34m(self, args, captured_inputs, cancellation_manager)\u001b[0m\n\u001b[0;32m   1744\u001b[0m       \u001b[1;31m# No tape is watching; skip to running the function.\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[1;32m-> 1745\u001b[1;33m       return self._build_call_outputs(self._inference_function.call(\n\u001b[0m\u001b[0;32m   1746\u001b[0m           ctx, args, cancellation_manager=cancellation_manager))\n",
      "\u001b[1;32m~\\anaconda3_64\\lib\\site-packages\\tensorflow\\python\\eager\\function.py\u001b[0m in \u001b[0;36mcall\u001b[1;34m(self, ctx, args, cancellation_manager)\u001b[0m\n\u001b[0;32m    592\u001b[0m         \u001b[1;32mif\u001b[0m \u001b[0mcancellation_manager\u001b[0m \u001b[1;32mis\u001b[0m \u001b[1;32mNone\u001b[0m\u001b[1;33m:\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[1;32m--> 593\u001b[1;33m           outputs = execute.execute(\n\u001b[0m\u001b[0;32m    594\u001b[0m               \u001b[0mstr\u001b[0m\u001b[1;33m(\u001b[0m\u001b[0mself\u001b[0m\u001b[1;33m.\u001b[0m\u001b[0msignature\u001b[0m\u001b[1;33m.\u001b[0m\u001b[0mname\u001b[0m\u001b[1;33m)\u001b[0m\u001b[1;33m,\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n",
      "\u001b[1;32m~\\anaconda3_64\\lib\\site-packages\\tensorflow\\python\\eager\\execute.py\u001b[0m in \u001b[0;36mquick_execute\u001b[1;34m(op_name, num_outputs, inputs, attrs, ctx, name)\u001b[0m\n\u001b[0;32m     58\u001b[0m     \u001b[0mctx\u001b[0m\u001b[1;33m.\u001b[0m\u001b[0mensure_initialized\u001b[0m\u001b[1;33m(\u001b[0m\u001b[1;33m)\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[1;32m---> 59\u001b[1;33m     tensors = pywrap_tfe.TFE_Py_Execute(ctx._handle, device_name, op_name,\n\u001b[0m\u001b[0;32m     60\u001b[0m                                         inputs, attrs, num_outputs)\n",
      "\u001b[1;31mUnknownError\u001b[0m:  Failed to get convolution algorithm. This is probably because cuDNN failed to initialize, so try looking to see if a warning log message was printed above.\n\t [[node sequential/conv2d/Conv2D (defined at <ipython-input-5-4c3041d4c086>:12) ]] [Op:__inference_train_function_4164]\n\nFunction call stack:\ntrain_function\n",
      "\nDuring handling of the above exception, another exception occurred:\n",
      "\u001b[1;31mAttributeError\u001b[0m                            Traceback (most recent call last)",
      "\u001b[1;32m~\\anaconda3_64\\lib\\site-packages\\IPython\\core\\interactiveshell.py\u001b[0m in \u001b[0;36mshowtraceback\u001b[1;34m(self, exc_tuple, filename, tb_offset, exception_only, running_compiled_code)\u001b[0m\n\u001b[0;32m   2044\u001b[0m                         \u001b[1;31m# in the engines. This should return a list of strings.\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[1;32m-> 2045\u001b[1;33m                         \u001b[0mstb\u001b[0m \u001b[1;33m=\u001b[0m \u001b[0mvalue\u001b[0m\u001b[1;33m.\u001b[0m\u001b[0m_render_traceback_\u001b[0m\u001b[1;33m(\u001b[0m\u001b[1;33m)\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0m\u001b[0;32m   2046\u001b[0m                     \u001b[1;32mexcept\u001b[0m \u001b[0mException\u001b[0m\u001b[1;33m:\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n",
      "\u001b[1;31mAttributeError\u001b[0m: 'UnknownError' object has no attribute '_render_traceback_'",
      "\nDuring handling of the above exception, another exception occurred:\n",
      "\u001b[1;31mTypeError\u001b[0m                                 Traceback (most recent call last)",
      "    \u001b[1;31m[... skipping hidden 1 frame]\u001b[0m\n",
      "\u001b[1;32m~\\anaconda3_64\\lib\\site-packages\\IPython\\core\\interactiveshell.py\u001b[0m in \u001b[0;36mshowtraceback\u001b[1;34m(self, exc_tuple, filename, tb_offset, exception_only, running_compiled_code)\u001b[0m\n\u001b[0;32m   2045\u001b[0m                         \u001b[0mstb\u001b[0m \u001b[1;33m=\u001b[0m \u001b[0mvalue\u001b[0m\u001b[1;33m.\u001b[0m\u001b[0m_render_traceback_\u001b[0m\u001b[1;33m(\u001b[0m\u001b[1;33m)\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0;32m   2046\u001b[0m                     \u001b[1;32mexcept\u001b[0m \u001b[0mException\u001b[0m\u001b[1;33m:\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[1;32m-> 2047\u001b[1;33m                         stb = self.InteractiveTB.structured_traceback(etype,\n\u001b[0m\u001b[0;32m   2048\u001b[0m                                             value, tb, tb_offset=tb_offset)\n\u001b[0;32m   2049\u001b[0m \u001b[1;33m\u001b[0m\u001b[0m\n",
      "\u001b[1;32m~\\anaconda3_64\\lib\\site-packages\\IPython\\core\\ultratb.py\u001b[0m in \u001b[0;36mstructured_traceback\u001b[1;34m(self, etype, value, tb, tb_offset, number_of_lines_of_context)\u001b[0m\n\u001b[0;32m   1434\u001b[0m         \u001b[1;32melse\u001b[0m\u001b[1;33m:\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0;32m   1435\u001b[0m             \u001b[0mself\u001b[0m\u001b[1;33m.\u001b[0m\u001b[0mtb\u001b[0m \u001b[1;33m=\u001b[0m \u001b[0mtb\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[1;32m-> 1436\u001b[1;33m         return FormattedTB.structured_traceback(\n\u001b[0m\u001b[0;32m   1437\u001b[0m             self, etype, value, tb, tb_offset, number_of_lines_of_context)\n\u001b[0;32m   1438\u001b[0m \u001b[1;33m\u001b[0m\u001b[0m\n",
      "\u001b[1;32m~\\anaconda3_64\\lib\\site-packages\\IPython\\core\\ultratb.py\u001b[0m in \u001b[0;36mstructured_traceback\u001b[1;34m(self, etype, value, tb, tb_offset, number_of_lines_of_context)\u001b[0m\n\u001b[0;32m   1334\u001b[0m         \u001b[1;32mif\u001b[0m \u001b[0mmode\u001b[0m \u001b[1;32min\u001b[0m \u001b[0mself\u001b[0m\u001b[1;33m.\u001b[0m\u001b[0mverbose_modes\u001b[0m\u001b[1;33m:\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0;32m   1335\u001b[0m             \u001b[1;31m# Verbose modes need a full traceback\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[1;32m-> 1336\u001b[1;33m             return VerboseTB.structured_traceback(\n\u001b[0m\u001b[0;32m   1337\u001b[0m                 \u001b[0mself\u001b[0m\u001b[1;33m,\u001b[0m \u001b[0metype\u001b[0m\u001b[1;33m,\u001b[0m \u001b[0mvalue\u001b[0m\u001b[1;33m,\u001b[0m \u001b[0mtb\u001b[0m\u001b[1;33m,\u001b[0m \u001b[0mtb_offset\u001b[0m\u001b[1;33m,\u001b[0m \u001b[0mnumber_of_lines_of_context\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0;32m   1338\u001b[0m             )\n",
      "\u001b[1;32m~\\anaconda3_64\\lib\\site-packages\\IPython\\core\\ultratb.py\u001b[0m in \u001b[0;36mstructured_traceback\u001b[1;34m(self, etype, evalue, etb, tb_offset, number_of_lines_of_context)\u001b[0m\n\u001b[0;32m   1191\u001b[0m         \u001b[1;34m\"\"\"Return a nice text document describing the traceback.\"\"\"\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0;32m   1192\u001b[0m \u001b[1;33m\u001b[0m\u001b[0m\n\u001b[1;32m-> 1193\u001b[1;33m         formatted_exception = self.format_exception_as_a_whole(etype, evalue, etb, number_of_lines_of_context,\n\u001b[0m\u001b[0;32m   1194\u001b[0m                                                                tb_offset)\n\u001b[0;32m   1195\u001b[0m \u001b[1;33m\u001b[0m\u001b[0m\n",
      "\u001b[1;32m~\\anaconda3_64\\lib\\site-packages\\IPython\\core\\ultratb.py\u001b[0m in \u001b[0;36mformat_exception_as_a_whole\u001b[1;34m(self, etype, evalue, etb, number_of_lines_of_context, tb_offset)\u001b[0m\n\u001b[0;32m   1149\u001b[0m \u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0;32m   1150\u001b[0m \u001b[1;33m\u001b[0m\u001b[0m\n\u001b[1;32m-> 1151\u001b[1;33m         \u001b[0mlast_unique\u001b[0m\u001b[1;33m,\u001b[0m \u001b[0mrecursion_repeat\u001b[0m \u001b[1;33m=\u001b[0m \u001b[0mfind_recursion\u001b[0m\u001b[1;33m(\u001b[0m\u001b[0morig_etype\u001b[0m\u001b[1;33m,\u001b[0m \u001b[0mevalue\u001b[0m\u001b[1;33m,\u001b[0m \u001b[0mrecords\u001b[0m\u001b[1;33m)\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0m\u001b[0;32m   1152\u001b[0m \u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0;32m   1153\u001b[0m         \u001b[0mframes\u001b[0m \u001b[1;33m=\u001b[0m \u001b[0mself\u001b[0m\u001b[1;33m.\u001b[0m\u001b[0mformat_records\u001b[0m\u001b[1;33m(\u001b[0m\u001b[0mrecords\u001b[0m\u001b[1;33m,\u001b[0m \u001b[0mlast_unique\u001b[0m\u001b[1;33m,\u001b[0m \u001b[0mrecursion_repeat\u001b[0m\u001b[1;33m)\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n",
      "\u001b[1;32m~\\anaconda3_64\\lib\\site-packages\\IPython\\core\\ultratb.py\u001b[0m in \u001b[0;36mfind_recursion\u001b[1;34m(etype, value, records)\u001b[0m\n\u001b[0;32m    449\u001b[0m     \u001b[1;31m# first frame (from in to out) that looks different.\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0;32m    450\u001b[0m     \u001b[1;32mif\u001b[0m \u001b[1;32mnot\u001b[0m \u001b[0mis_recursion_error\u001b[0m\u001b[1;33m(\u001b[0m\u001b[0metype\u001b[0m\u001b[1;33m,\u001b[0m \u001b[0mvalue\u001b[0m\u001b[1;33m,\u001b[0m \u001b[0mrecords\u001b[0m\u001b[1;33m)\u001b[0m\u001b[1;33m:\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[1;32m--> 451\u001b[1;33m         \u001b[1;32mreturn\u001b[0m \u001b[0mlen\u001b[0m\u001b[1;33m(\u001b[0m\u001b[0mrecords\u001b[0m\u001b[1;33m)\u001b[0m\u001b[1;33m,\u001b[0m \u001b[1;36m0\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0m\u001b[0;32m    452\u001b[0m \u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0;32m    453\u001b[0m     \u001b[1;31m# Select filename, lineno, func_name to track frames with\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n",
      "\u001b[1;31mTypeError\u001b[0m: object of type 'NoneType' has no len()"
     ]
    }
   ],
   "source": [
    "answers = np.ndarray((num_mod, ans.shape[0]))\n",
    "\n",
    "weights_file = 'weights.hdf5'\n",
    "checkpoint = tf.keras.callbacks.ModelCheckpoint(weights_file, monitor='acc')\n",
    "\n",
    "for i in range(num_mod):\n",
    "    models[i].compile(\n",
    "    optimizer='adam',\n",
    "    loss='sparse_categorical_crossentropy',\n",
    "    metrics=['accuracy']) \n",
    "    \n",
    "    models[i].fit(data.reshape(-1, 32, 32, 1), ans, epochs=3, batch_size = 3*(i+1), callbacks=[checkpoint])\n",
    "    answers[i] = np.argmax(models[i].predict(meta_data.reshape(-1, 32, 32, 1)), axis = 1)\n",
    "    \n",
    "answer = answers.transpose()\n",
    "\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "metadata": {},
   "outputs": [
    {
     "ename": "NameError",
     "evalue": "name 'answer' is not defined",
     "output_type": "error",
     "traceback": [
      "\u001b[1;31m---------------------------------------------------------------------------\u001b[0m",
      "\u001b[1;31mNameError\u001b[0m                                 Traceback (most recent call last)",
      "\u001b[1;32m<ipython-input-4-21c2da736472>\u001b[0m in \u001b[0;36m<module>\u001b[1;34m\u001b[0m\n\u001b[0;32m     12\u001b[0m     metrics=['accuracy'])\n\u001b[0;32m     13\u001b[0m \u001b[1;33m\u001b[0m\u001b[0m\n\u001b[1;32m---> 14\u001b[1;33m \u001b[0mmodel\u001b[0m\u001b[1;33m.\u001b[0m\u001b[0mfit\u001b[0m\u001b[1;33m(\u001b[0m\u001b[0manswer\u001b[0m\u001b[1;33m.\u001b[0m\u001b[0mreshape\u001b[0m\u001b[1;33m(\u001b[0m\u001b[1;33m-\u001b[0m\u001b[1;36m1\u001b[0m\u001b[1;33m,\u001b[0m \u001b[0mnum_mod\u001b[0m\u001b[1;33m,\u001b[0m \u001b[1;36m1\u001b[0m\u001b[1;33m)\u001b[0m\u001b[1;33m,\u001b[0m \u001b[0mmeta_ans\u001b[0m\u001b[1;33m,\u001b[0m \u001b[0mepochs\u001b[0m\u001b[1;33m=\u001b[0m\u001b[1;36m10\u001b[0m\u001b[1;33m,\u001b[0m \u001b[0mbatch_size\u001b[0m \u001b[1;33m=\u001b[0m \u001b[1;36m5\u001b[0m\u001b[1;33m,\u001b[0m \u001b[0mcallbacks\u001b[0m\u001b[1;33m=\u001b[0m\u001b[1;33m[\u001b[0m\u001b[0mcheckpoint\u001b[0m\u001b[1;33m]\u001b[0m\u001b[1;33m)\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0m\u001b[0;32m     15\u001b[0m \u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0;32m     16\u001b[0m \u001b[0md_test\u001b[0m \u001b[1;33m=\u001b[0m \u001b[0mnp\u001b[0m\u001b[1;33m.\u001b[0m\u001b[0mndarray\u001b[0m\u001b[1;33m(\u001b[0m\u001b[1;33m(\u001b[0m\u001b[0mnum_mod\u001b[0m\u001b[1;33m,\u001b[0m \u001b[0mresult_test\u001b[0m\u001b[1;33m.\u001b[0m\u001b[0mshape\u001b[0m\u001b[1;33m[\u001b[0m\u001b[1;36m0\u001b[0m\u001b[1;33m]\u001b[0m\u001b[1;33m)\u001b[0m\u001b[1;33m)\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n",
      "\u001b[1;31mNameError\u001b[0m: name 'answer' is not defined"
     ]
    }
   ],
   "source": [
    "model = tf.keras.models.Sequential([\n",
    "    tf.keras.layers.Conv1D(input_shape=(num_mod,1), filters=10, kernel_size=20, padding='same', activation='relu'),\n",
    "    tf.keras.layers.MaxPool1D(pool_size=2),\n",
    "    tf.keras.layers.Flatten(),\n",
    "    tf.keras.layers.Dense(num_mod*3, activation=tf.nn.relu),\n",
    "    tf.keras.layers.Dense(num_classes, activation=tf.nn.softmax)\n",
    "])\n",
    "\n",
    "model.compile(\n",
    "    optimizer='adam',\n",
    "    loss='sparse_categorical_crossentropy',\n",
    "    metrics=['accuracy'])\n",
    "\n",
    "model.fit(answer.reshape(-1, num_mod, 1), meta_ans, epochs=10, batch_size = 5, callbacks=[checkpoint])\n",
    "\n",
    "d_test = np.ndarray((num_mod, result_test.shape[0]))\n",
    "for i in range(num_mod):\n",
    "    d_test[i] = np.argmax(models[i].predict(Y_test.reshape(-1, 32, 32, 1)), axis = 1)\n",
    "    \n",
    "d_test = d_test.transpose()\n",
    "most, mostcc = scipy.stats.mode(d_test, axis=1)\n",
    "\n",
    "mist = 0\n",
    "most.reshape(most.shape[0],)\n",
    "for i in range(most.shape[0]):\n",
    "    if most[i] != result_test[i]:\n",
    "        mist += 1/most.shape[0]\n",
    "print(mist)\n",
    "\n",
    "model.evaluate(d_test.reshape(-1, num_mod, 1), result_test)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 108,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Epoch 1/3\n",
      "500/500 [==============================] - 2s 3ms/step - loss: 0.2499 - accuracy: 0.9738\n",
      "Epoch 2/3\n",
      "500/500 [==============================] - 2s 3ms/step - loss: 0.2305 - accuracy: 0.9758\n",
      "Epoch 3/3\n",
      "500/500 [==============================] - 2s 3ms/step - loss: 0.2234 - accuracy: 0.9682\n",
      "0.015009380863039403\n",
      "17/17 [==============================] - 0s 3ms/step - loss: 0.4889 - accuracy: 0.9756\n"
     ]
    },
    {
     "data": {
      "text/plain": [
       "[0.48891913890838623, 0.9756097793579102]"
      ]
     },
     "execution_count": 108,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "model.fit(answer, meta_ans, epochs=3, batch_size = 10, callbacks=[checkpoint])\n",
    "\n",
    "d_test = np.ndarray((num_mod, result_test.shape[0]))\n",
    "for i in range(num_mod):\n",
    "    d_test[i] = np.argmax(models[i].predict(Y_test.reshape(-1, 32, 32, 1)), axis = 1)\n",
    "    \n",
    "d_test = d_test.transpose()\n",
    "most, mostcc = scipy.stats.mode(d_test, axis=1)\n",
    "\n",
    "mist = 0\n",
    "most.reshape(most.shape[0],)\n",
    "for i in range(most.shape[0]):\n",
    "    if most[i] != result_test[i]:\n",
    "        mist += 1/most.shape[0]\n",
    "print(mist)\n",
    "\n",
    "model.evaluate(d_test, result_test)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 67,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Epoch 1/4\n",
      "334/334 [==============================] - 3s 8ms/step - loss: 0.9000 - accuracy: 0.7107\n",
      "Epoch 2/4\n",
      "334/334 [==============================] - 3s 8ms/step - loss: 0.0757 - accuracy: 0.9764\n",
      "Epoch 3/4\n",
      "334/334 [==============================] - 3s 8ms/step - loss: 0.0380 - accuracy: 0.9899\n",
      "Epoch 4/4\n",
      "334/334 [==============================] - 3s 8ms/step - loss: 0.0306 - accuracy: 0.9922\n",
      "17/17 [==============================] - 0s 9ms/step - loss: 0.1291 - accuracy: 0.9850\n"
     ]
    },
    {
     "data": {
      "text/plain": [
       "[0.12913687527179718, 0.9849905967712402]"
      ]
     },
     "execution_count": 67,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "model_211 = tf.keras.models.Sequential([\n",
    "    tf.keras.layers.Conv2D(input_shape=(32, 32, 1), filters=52, kernel_size=(2,4), padding='same', activation='relu'),\n",
    "    tf.keras.layers.MaxPool2D(pool_size=(2, 2)),\n",
    "    tf.keras.layers.Conv2D(filters=86, kernel_size=(2,4), padding='same', activation='relu'),\n",
    "    tf.keras.layers.MaxPool2D(pool_size=(2, 2)),\n",
    "    tf.keras.layers.Flatten(),\n",
    "    tf.keras.layers.Dense(512, activation=tf.nn.relu),\n",
    "    tf.keras.layers.Dense(num_classes, activation=tf.nn.softmax)\n",
    "])\n",
    "\n",
    "model_211.compile(\n",
    "    optimizer='adam',\n",
    "    loss='sparse_categorical_crossentropy',\n",
    "    metrics=['accuracy'])\n",
    "\n",
    "model_211.fit(data.reshape(-1, 32, 32, 1), ans, epochs=4, batch_size = 15, callbacks=[checkpoint])\n",
    "model_211.evaluate(Y_test.reshape(-1, 32, 32, 1), result_test)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 72,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "<matplotlib.image.AxesImage at 0x223cfdfec70>"
      ]
     },
     "execution_count": 72,
     "metadata": {},
     "output_type": "execute_result"
    },
    {
     "data": {
      "image/png": "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\n",
      "text/plain": [
       "<Figure size 432x288 with 1 Axes>"
      ]
     },
     "metadata": {
      "needs_background": "light"
     },
     "output_type": "display_data"
    }
   ],
   "source": [
    "io.imshow(Y[0])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 70,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "(2131, 32, 32)"
      ]
     },
     "execution_count": 70,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "Y.shape"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 74,
   "metadata": {},
   "outputs": [],
   "source": [
    "from skimage.feature import hog\n",
    "features = hog(Y[0], orientations=8,\n",
    "pixels_per_cell=(4, 4),\n",
    "cells_per_block=(1, 1))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 76,
   "metadata": {},
   "outputs": [],
   "source": [
    "hog_data = []\n",
    "for im in data:\n",
    "    features = hog(im, orientations=8,\n",
    "pixels_per_cell=(4, 4),\n",
    "cells_per_block=(1, 1))\n",
    "    hog_data.append(features)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 80,
   "metadata": {},
   "outputs": [],
   "source": [
    "hog_data = np.asarray(hog_data)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 95,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Epoch 1/8\n",
      "334/334 [==============================] - 11s 29ms/step - loss: 2.2453 - accuracy: 0.2093\n",
      "Epoch 2/8\n",
      "334/334 [==============================] - 10s 29ms/step - loss: 2.0383 - accuracy: 0.2784\n",
      "Epoch 3/8\n",
      "334/334 [==============================] - 10s 29ms/step - loss: 0.4252 - accuracy: 0.8827\n",
      "Epoch 4/8\n",
      "334/334 [==============================] - 10s 29ms/step - loss: 0.2262 - accuracy: 0.9365\n",
      "Epoch 5/8\n",
      "334/334 [==============================] - 10s 29ms/step - loss: 0.1450 - accuracy: 0.9572\n",
      "Epoch 6/8\n",
      "334/334 [==============================] - 10s 29ms/step - loss: 0.1037 - accuracy: 0.9725\n",
      "Epoch 7/8\n",
      "334/334 [==============================] - 10s 29ms/step - loss: 0.0815 - accuracy: 0.98070s - loss: 0.0813 - accu\n",
      "Epoch 8/8\n",
      "334/334 [==============================] - 10s 29ms/step - loss: 0.0707 - accuracy: 0.98290s - loss: 0\n"
     ]
    },
    {
     "data": {
      "text/plain": [
       "<tensorflow.python.keras.callbacks.History at 0x223c2393790>"
      ]
     },
     "execution_count": 95,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "model = tf.keras.models.Sequential([\n",
    "    tf.keras.layers.Conv1D(input_shape=(hog_data.shape[1],1), filters=128, kernel_size=52, padding='same', activation='softmax'),\n",
    "    tf.keras.layers.MaxPool1D(pool_size=2),\n",
    "    tf.keras.layers.Conv1D(filters=256, kernel_size=26, padding='same', activation='softmax'),\n",
    "    tf.keras.layers.MaxPool1D(pool_size=2),\n",
    "    tf.keras.layers.Flatten(),\n",
    "    tf.keras.layers.Dense(num_mod*3, activation=tf.nn.relu),\n",
    "    tf.keras.layers.Dense(num_classes, activation=tf.nn.softmax)\n",
    "])\n",
    "\n",
    "model.compile(\n",
    "    optimizer='adam',\n",
    "    loss='sparse_categorical_crossentropy',\n",
    "    metrics=['accuracy'])\n",
    "\n",
    "model.fit(hog_data.reshape(-1, hog_data.shape[1], 1), ans, epochs=8, batch_size = 15, callbacks=[checkpoint])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 1,
   "metadata": {},
   "outputs": [
    {
     "ename": "NameError",
     "evalue": "name 'Y_test' is not defined",
     "output_type": "error",
     "traceback": [
      "\u001b[1;31m---------------------------------------------------------------------------\u001b[0m",
      "\u001b[1;31mNameError\u001b[0m                                 Traceback (most recent call last)",
      "\u001b[1;32m<ipython-input-1-bd29dbaa3704>\u001b[0m in \u001b[0;36m<module>\u001b[1;34m\u001b[0m\n\u001b[0;32m      1\u001b[0m \u001b[0mhog_test\u001b[0m \u001b[1;33m=\u001b[0m \u001b[1;33m[\u001b[0m\u001b[1;33m]\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[1;32m----> 2\u001b[1;33m \u001b[1;32mfor\u001b[0m \u001b[0mim\u001b[0m \u001b[1;32min\u001b[0m \u001b[0mY_test\u001b[0m\u001b[1;33m:\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0m\u001b[0;32m      3\u001b[0m     features = hog(im, orientations=8,\n\u001b[0;32m      4\u001b[0m \u001b[0mpixels_per_cell\u001b[0m\u001b[1;33m=\u001b[0m\u001b[1;33m(\u001b[0m\u001b[1;36m4\u001b[0m\u001b[1;33m,\u001b[0m \u001b[1;36m4\u001b[0m\u001b[1;33m)\u001b[0m\u001b[1;33m,\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0;32m      5\u001b[0m cells_per_block=(1, 1))\n",
      "\u001b[1;31mNameError\u001b[0m: name 'Y_test' is not defined"
     ]
    }
   ],
   "source": [
    "hog_test = []\n",
    "for im in Y_test:\n",
    "    features = hog(im, orientations=8,\n",
    "pixels_per_cell=(4, 4),\n",
    "cells_per_block=(1, 1))\n",
    "    hog_test.append(features)\n",
    "    \n",
    "hog_test = np.asarray(hog_test)\n",
    "model.evaluate(hog_test.reshape(-1, hog_data.shape[1], 1), result_test)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.8.5"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 4
}
